{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# installing and updating nikola"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%conda install -c asmeurer nikola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: Nikola 8.1.1\n",
      "Uninstalling Nikola-8.1.1:\n",
      "  Successfully uninstalled Nikola-8.1.1\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip uninstall -y nikola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T10:24:17.333057Z",
     "start_time": "2018-09-07T10:24:14.585077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Nikola[extras]\n",
      "  Downloading Nikola-8.1.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 188 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: Pygments>=1.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (2.7.2)\n",
      "Collecting unidecode>=0.04.16\n",
      "  Using cached Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "Collecting piexif>=1.0.3\n",
      "  Using cached piexif-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=2.4.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (8.0.1)\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/bf/9e/da/ae737eed8571fd12cda587823af906e5bf4db0a43091017602/PyRSS2Gen-1.1-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: lxml>=3.3.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (4.6.1)\n",
      "Collecting natsort>=3.5.2\n",
      "  Downloading natsort-7.1.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=24.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (50.3.1.post20201107)\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/b7/a5/68/fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4/blinker-1.4-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (2.8.1)\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/da/b4/b7/500e17e7611250b358a234e4fa4010d08228ef0e46015f61ea/Yapsy-1.12.2-py3-none-any.whl\n",
      "Collecting mako>=1.0.0\n",
      "  Using cached Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting Markdown>=3.0.0\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied, skipping upgrade: docutils>=0.13 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (0.16)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (2.8.1)\n",
      "Collecting doit>=0.32.0\n",
      "  Using cached doit-0.33.1-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.0.0; extra == \"extras\" in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (5.3.4)\n",
      "Collecting pygal>=2.0.0; extra == \"extras\"\n",
      "  Using cached pygal-2.4.0-py2.py3-none-any.whl (127 kB)\n",
      "Collecting ghp-import2>=1.0.0; extra == \"extras\"\n",
      "  Using cached ghp_import2-1.0.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.7.2; extra == \"extras\" in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: toml>=0.9.2; extra == \"extras\" in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (0.10.1)\n",
      "Collecting aiohttp>=3.0.0; extra == \"extras\"\n",
      "  Downloading aiohttp-3.7.3-cp38-cp38-macosx_10_14_x86_64.whl (647 kB)\n",
      "\u001b[K     |████████████████████████████████| 647 kB 179 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyphen>=0.9.1; extra == \"extras\"\n",
      "  Using cached Pyphen-0.10.0-py3-none-any.whl (1.9 MB)\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/22/81/a7/9869b61a68fb27d3b2a81a3b186a0b5195cb06de96a6c56afb/phpserialize-1.3-py3-none-any.whl\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/0b/e9/98/c888501e8dd2166da059e4f8418694de9b50b48a7192712be9/typogrify-2.0.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml>=0.15; extra == \"extras\" in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (0.15.87)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=4.0.0; extra == \"extras\" in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (6.1.4)\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/f4/8d/27/0489d1d151f6e32fd879e165c4da1f2de95013d2afd4632366/husl-4.0.3-py3-none-any.whl\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/ab/e4/62/04f67244fffa7c74b0cfaee1a6093249a114c824144c1e9e5b/micawber-0.5.1-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: watchdog>=0.8.3; extra == \"extras\" in /usr/local/anaconda3/lib/python3.8/site-packages (from Nikola[extras]) (0.10.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests>=2.2.0->Nikola[extras]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests>=2.2.0->Nikola[extras]) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests>=2.2.0->Nikola[extras]) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests>=2.2.0->Nikola[extras]) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2015.7 in /usr/local/anaconda3/lib/python3.8/site-packages (from Babel>=2.6.0->Nikola[extras]) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from mako>=1.0.0->Nikola[extras]) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.0->Nikola[extras]) (1.15.0)\n",
      "Processing /Users/laurentperrinet/Library/Caches/pip/wheels/8e/30/68/60d6a1c29ee042a187641d213879baaf5d9ae45243105579bb/MacFSEvents-0.8.1-cp38-cp38-macosx_10_15_x86_64.whl\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /usr/local/anaconda3/lib/python3.8/site-packages (from doit>=0.32.0->Nikola[extras]) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=5.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (7.19.0)\n",
      "Requirement already satisfied, skipping upgrade: appnope; platform_system == \"Darwin\" in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (6.1.7)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (5.0.5)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.0.2-cp38-cp38-macosx_10_14_x86_64.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 153 kB/s eta 0:00:01     |█████████████▍                  | 20 kB 97 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.0.0; extra == \"extras\"->Nikola[extras]) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp>=3.0.0; extra == \"extras\"->Nikola[extras]) (20.3.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp38-cp38-macosx_10_14_x86_64.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 100 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smartypants>=1.8.3\n",
      "  Using cached smartypants-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: nbformat in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (5.0.8)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (19.0.2)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: argon2-cffi in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (20.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /usr/local/anaconda3/lib/python3.8/site-packages (from notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (6.0.7)\n",
      "Requirement already satisfied, skipping upgrade: pathtools>=0.1.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from watchdog>=0.8.3; extra == \"extras\"->Nikola[extras]) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pexpect>4.3; sys_platform != \"win32\" in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (3.0.8)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /usr/local/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess in /usr/local/anaconda3/lib/python3.8/site-packages (from terminado>=0.8.3->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbformat->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: nbclient<0.6.0,>=0.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (1.4.3)\n",
      "Requirement already satisfied, skipping upgrade: jupyterlab-pygments in /usr/local/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: parso<0.8.0,>=0.7.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/anaconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (2.20)\n",
      "Requirement already satisfied, skipping upgrade: async-generator in /usr/local/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (1.10)\n",
      "Requirement already satisfied, skipping upgrade: nest-asyncio in /usr/local/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.0.0; extra == \"extras\"->Nikola[extras]) (2.4.7)\n",
      "Installing collected packages: unidecode, piexif, PyRSS2Gen, natsort, blinker, Yapsy, mako, Markdown, macfsevents, doit, pygal, ghp-import2, multidict, async-timeout, yarl, aiohttp, pyphen, phpserialize, smartypants, typogrify, husl, micawber, Nikola\n",
      "Successfully installed Markdown-3.3.3 Nikola-8.1.2 PyRSS2Gen-1.1 Yapsy-1.12.2 aiohttp-3.7.3 async-timeout-3.0.1 blinker-1.4 doit-0.33.1 ghp-import2-1.0.1 husl-4.0.3 macfsevents-0.8.1 mako-1.1.3 micawber-0.5.1 multidict-5.0.2 natsort-7.1.0 phpserialize-1.3 piexif-1.1.3 pygal-2.4.0 pyphen-0.10.0 smartypants-2.0.1 typogrify-2.0.7 unidecode-1.1.1 yarl-1.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"Nikola[extras]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T10:24:48.097536Z",
     "start_time": "2018-09-07T10:24:43.118411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rst2html5\n",
      "  Using cached rst2html5-1.10.6-py2.py3-none-any.whl (19 kB)\n",
      "Collecting pygments>=2.0.2\n",
      "  Using cached Pygments-2.7.1-py3-none-any.whl (944 kB)\n",
      "Collecting docutils>=0.14\n",
      "  Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "Collecting genshi>=0.7\n",
      "  Using cached Genshi-0.7.3-py3-none-any.whl (178 kB)\n",
      "Installing collected packages: pygments, docutils, genshi, rst2html5\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.7.1\n",
      "    Uninstalling Pygments-2.7.1:\n",
      "      Successfully uninstalled Pygments-2.7.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "  Attempting uninstall: genshi\n",
      "    Found existing installation: Genshi 0.7.3\n",
      "    Uninstalling Genshi-0.7.3:\n",
      "      Successfully uninstalled Genshi-0.7.3\n",
      "  Attempting uninstall: rst2html5\n",
      "    Found existing installation: rst2html5 1.10.6\n",
      "    Uninstalling rst2html5-1.10.6:\n",
      "      Successfully uninstalled rst2html5-1.10.6\n",
      "Successfully installed docutils-0.16 genshi-0.7.3 pygments-2.7.1 rst2html5-1.10.6\n"
     ]
    }
   ],
   "source": [
    "#!python3 -m pip uninstall -y rst2html5\n",
    "!python3 -m pip install -U --force rst2html5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T10:24:57.383520Z",
     "start_time": "2018-09-07T10:24:54.879696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting six>=1.9\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: webencodings, six, html5lib\n",
      "  Attempting uninstall: webencodings\n",
      "    Found existing installation: webencodings 0.5.1\n",
      "    Uninstalling webencodings-0.5.1:\n",
      "      Successfully uninstalled webencodings-0.5.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: html5lib\n",
      "    Found existing installation: html5lib 1.1\n",
      "    Uninstalling html5lib-1.1:\n",
      "      Successfully uninstalled html5lib-1.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "astroid 2.4.2 requires lazy-object-proxy==1.4.*, but you'll have lazy-object-proxy 1.5.1 which is incompatible.\u001b[0m\n",
      "Successfully installed html5lib-1.1 six-1.15.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall -y html5lib\n",
    "!python3 -m pip install -U --force html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T10:24:57.383520Z",
     "start_time": "2018-09-07T10:24:54.879696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/site-packages (20.2.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall -y html5lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T10:25:37.163105Z",
     "start_time": "2018-09-07T10:25:34.804602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nikola v8.1.2\n"
     ]
    }
   ],
   "source": [
    "!nikola version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T10:25:40.747475Z",
     "start_time": "2018-09-07T10:25:38.376282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nikola v8.1.2\n",
      "Nikola is up-to-date\n"
     ]
    }
   ],
   "source": [
    "!nikola version --check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:34:58.343345Z",
     "start_time": "2018-11-05T14:34:58.224501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 24 15:18:49 CET 2020\n"
     ]
    }
   ],
   "source": [
    "!date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:34:58.697822Z",
     "start_time": "2018-11-05T14:34:58.694703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-24 15:18:49.881766\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:34:59.176807Z",
     "start_time": "2018-11-05T14:34:59.173942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-24\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now().date()\n",
    "date = now.isoformat()#[2:]\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:34:58.343345Z",
     "start_time": "2018-11-05T14:34:58.224501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-24\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "date = datetime.datetime.now().date().isoformat()\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m Return string in ISO 8601 format, YYYY-MM-DD.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "now.isoformat?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "date = '2019-10-07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:35:00.048738Z",
     "start_time": "2018-11-05T14:34:59.677518Z"
    }
   },
   "outputs": [],
   "source": [
    "from nikola import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:40:53.234519Z",
     "start_time": "2018-11-05T14:40:53.230930Z"
    }
   },
   "outputs": [],
   "source": [
    "tags_list = [\n",
    "    'python', \n",
    "#    'ipython', \n",
    "#    'jupyter', \n",
    "#    'nikola', \n",
    "    'blog', \n",
    "#    'themes', \n",
    "#    'pupil',\n",
    "#    'psychophysics',\n",
    "#    'outreach',    'grand-public',\n",
    "#   'behavior',\n",
    "#    'povray', \n",
    "#    'elasticite', \n",
    "#    'art', \n",
    "#    'trames', \n",
    "#    'math',\n",
    "#    'bicv', \n",
    "#    'SLIP', \n",
    "#    'LogGabor', \n",
    "#    'SHL_scripts', \n",
    "#    'sparse', \n",
    "#    'Matching Pursuit',\n",
    "#    'Motion Particles',\n",
    "#    'holoviews',\n",
    "#    'pytorch',\n",
    "#    'deep-learning',\n",
    "#    'machine-learning',\n",
    "#    'moviepy', \n",
    "#     'numpy', \n",
    "#    'vispy', \n",
    "#    'neural',\n",
    "#    'motionclouds',\n",
    "#    'motion',\n",
    "#    'pynn',\n",
    "#    'saccades',\n",
    "#    'Free Energy',\n",
    "#    'learning',\n",
    "    'open-science',\n",
    "    'pandas',\n",
    "#    'shell',\n",
    "#    'vim',\n",
    "#    'orientation',\n",
    "#    'vision',\n",
    "#    'v1',\n",
    "]\n",
    "formt = 'rest'\n",
    "formt = 'markdown'\n",
    "formt = 'ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:01.475071Z",
     "start_time": "2018-11-05T14:41:00.415148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nikola new_post [options] [path]\n",
      "    create a new blog post or site page\n",
      "\n",
      "Options:\n",
      "    -p, --page\n",
      "        Create a page instead of a blog post. (see also: `nikola\n",
      "        new_page`)\n",
      "    -t ARG, --title=ARG\n",
      "        Title for the post.\n",
      "    -a ARG, --author=ARG\n",
      "        Author of the post.\n",
      "    --tags=ARG\n",
      "        Comma-separated tags for the post.\n",
      "    -1\n",
      "        Create the post with embedded metadata (single file format)\n",
      "    -2\n",
      "        Create the post with separate metadata (two file format)\n",
      "    -e\n",
      "        Open the post (and meta file, if any) in $EDITOR after\n",
      "        creation.\n",
      "    -f ARG, --format=ARG\n",
      "        Markup format for the post (use --available-formats for list)\n",
      "    -F, --available-formats\n",
      "        List all available input formats\n",
      "    -s\n",
      "        Schedule the post based on recurrence rule\n",
      "    -i ARG, --import=ARG\n",
      "        Import an existing file instead of creating a placeholder\n",
      "    -d, --date-path\n",
      "        Create post with date path (eg. year/month/day, see\n",
      "        NEW_POST_DATE_PATH_FORMAT in config)\n"
     ]
    }
   ],
   "source": [
    "!nikola new_post -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:01.475071Z",
     "start_time": "2018-11-05T14:41:00.415148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available input formats:\n",
      "\n",
      " NAME        DESCRIPTION       EXTENSIONS\n",
      "\n",
      " html        HTML              .html, .htm\n",
      " ipynb       Jupyter Notebook  .ipynb\n",
      " markdown    Markdown          .md, .mdown, .markdown\n",
      " rest        reStructuredText  .rst, .txt\n",
      "!php         PHP               .php\n",
      "~pandoc      Pandoc            (disabled: not in COMPILERS)\n",
      "~rest_html5  rest_html5        (disabled: not in COMPILERS)\n",
      "\n",
      "    More compilers are available in the Plugins Index.\n",
      "\n",
      "    Compilers marked with ! and ~ require additional configuration:\n",
      "        ! not in the POSTS/PAGES tuples and any post scanners (unused)\n",
      "        ~ not in the COMPILERS dict (disabled)\n",
      "    Read more: https://getnikola.com/handbook.html#configuring-other-input-formats\n"
     ]
    }
   ],
   "source": [
    "!nikola new_post  --available-formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:08.343633Z",
     "start_time": "2018-11-05T14:41:02.455292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating New Post\n",
      "-----------------\n",
      "\n",
      "Title: 2020-11-24 Extracting music from the screenshots of a Spotify playlist\n",
      "Scanning posts...........done!\n",
      "\u001b[1;33m[2020-11-24 15:19:07] WARNING: ipynb: No kernel specified, assuming \"python3\".\u001b[0m\n",
      "\u001b[1m[2020-11-24 15:19:07] INFO: new_post: Your post's metadata is at: posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.meta\u001b[0m\n",
      "\u001b[1m[2020-11-24 15:19:07] INFO: new_post: Your post's text is at: posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.ipynb\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tags = ', '.join(tags_list)\n",
    "title = date + ' ' + \"Extracting music from the screenshots of a Spotify playlist\"\n",
    "#title = '2017-12-13 accessing the data from a pupil recording'\n",
    "!nikola new_post -f \"{formt}\" -2 -t \"{title}\" --tags=\"{tags}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T10:17:49.012273Z",
     "start_time": "2018-11-08T10:17:49.005411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.ipynb\n"
     ]
    }
   ],
   "source": [
    "fname = utils.os.path.join('posts', utils.slugify(title) + '.' + formt)\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posts/2020-10-10-fitting-covid-data.ipynb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.shutil.copy('template.ipynb', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying existing notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Copy data and mode bits (\"cp src dst\"). Return the file's destination.\n",
       "\n",
       "The destination may be a directory.\n",
       "\n",
       "If follow_symlinks is false, symlinks won't be followed. This\n",
       "resembles GNU's \"cp -P src dst\".\n",
       "\n",
       "If source and destination are the same file, a SameFileError will be\n",
       "raised.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/shutil.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.shutil.copy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.ipynb'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nikola import utils\n",
    "utils.shutil.copy('/Users/laurentperrinet/quantic/Documents/downloads/PLayList-Etienne-2019/dev-Genius.ipynb', 'posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posts/2020-09-28-benchmarking-cnns.ipynb'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nikola import utils\n",
    "utils.shutil.copy('/Users/laurentperrinet/quantic/science/ActiveVision/2020_StageM1_Jean-Nicolas/2020-06-26_fast_and_curious/benchmark_image_recognition.ipynb', 'posts/2020-09-28-benchmarking-cnns.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posts/2020-06-19-caustic-optics.ipynb'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nikola import utils\n",
    "utils.shutil.copy('/Users/laurentperrinet/quantic/EtienneRey/2020_caustiques/2020-06-19_caustique.ipynb', 'posts/2020-06-19-caustic-optics.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [],
   "source": [
    "!nbdiff /Users/laurentperrinet/quantic/EtienneRey/2020_caustiques/2020-06-19_caustique.ipynb posts/2020-06-19-caustic-optics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'files/2020-06-19_caustique'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.shutil.rmtree('files/2020-06-19_caustique', ignore_errors=True)\n",
    "utils.shutil.copytree('/Users/laurentperrinet/quantic/EtienneRey/2020_caustiques/2020-06-19_caustique', 'files/2020-06-19_caustique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/laurentperrinet/quantic/EtienneRey/2020_caustiques/2020-06-19_caustique'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#utils.shutil.rmtree('/Users/laurentperrinet/quantic/EtienneRey/files', ignore_errors=True)\n",
    "#utils.shutil.move('/Users/laurentperrinet/quantic/EtienneRey/files/2020-06-19_caustique', '/Users/laurentperrinet/quantic/EtienneRey/2020_caustiques/2020-06-19_caustique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posts/2020-04-08-fitting-a-psychometric-curve-using-pytorch.ipynb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.shutil.copy('/Users/laurentperrinet/quantic/science/OBV1/jennafradin_MSc-Internship/Notebooks/W13/10_theory-fitting_psychometric.ipynb', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts/2015-05-22-a-hitchhiker-guide-to-matching-pursuit.ipynb\n",
      "posts/2015-05-22-a-hitchhiker-guide-to-matching-pursuit.meta\n"
     ]
    }
   ],
   "source": [
    "%ls posts/2015*hitch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T14:41:18.822843Z",
     "start_time": "2018-11-05T14:41:18.813958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posts/2019-11-28-role-of-gamma-correction-in-sparse-coding.ipynb'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.shutil.copy('posts/2015-05-22-a-hitchhiker-guide-to-matching-pursuit.ipynb', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T10:17:33.863368Z",
     "start_time": "2018-11-08T10:17:33.822970Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.shutil.copy('/Users/laurentperrinet/pool/TimeWarp/2018-11-05_Statistics of the natural input to a ring model.ipynb', fname)\n",
    "utils.shutil.copy('/Users/laurentperrinet/pool/TimeWarp/figs/2018-11-05_Ring_input.mp4', 'files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.shutil.copy('/Users/laurentperrinet//science/pupil/dev/2017-12-13 accessing the data from a pupil recording.ipynb', 'posts/2017-12-13-accessing-the-data-from-a-pupil-recording.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "titles = ['2017-03-29 testing COMPs-Pcum', '2017-03-29 testing COMPs-fastPcum', '2017-03-29 testing COMPs-fastPcum_scripted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ', '.join(tags_list)\n",
    "for title in titles:\n",
    "    !nikola new_post -f \"{formt}\" -2 -t \"{title}\" --tags=\"{tags}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    fname = utils.os.path.join('posts', utils.slugify(title) + '.' + formt)\n",
    "    print(fname)\n",
    "    import os\n",
    "    home = os.environ['HOME']\n",
    "    print(home)\n",
    "    filepath = home +  \"/science/VB_These/Rapport d'avancement/2017-03/\"\n",
    "    print(filepath + title +'.ipynb')\n",
    "    utils.shutil.copy(filepath + title +'.ipynb', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO : 2017-05-23-reproducing-olshausens-classical-sparsenet-part-5.ipynb and others from 2017-05-23-reproducing-olshausens-classical-sparsenet-part-5.ipynb\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below, I detail some thoughts on why it is a perfect preamble for most ipython notebooks.\n",
    "\n",
    "<!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import nikola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "nikola.utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nikola.plugins import commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plugins.absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!nikola help new_post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "base_url = \"http://127.0.0.1:\"\n",
    "port = 8889\n",
    "\n",
    "from nikola import utils\n",
    "notebook = \"/notebooks/posts/\" + utils.slugify(unicode(title)) + \".ipynb\"  \n",
    "\n",
    "url = base_url + str(port) + notebook\n",
    "print url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def convert(URL, DATE, TIME, TITLE, TAGS, doit=True):\n",
    "\n",
    "    TIMEDTITLE = DATE[2:] + ' ' + TITLE\n",
    "    SLUG = DATE[2:] + '-' + TITLE.replace(' ', '-')\n",
    "    tmplt = \"\"\"\\\n",
    ".. title: %s %s\n",
    ".. slug: %s\n",
    ".. date: %s %s\n",
    ".. type: text\n",
    ".. tags: %s\n",
    "    \n",
    "\"\"\" % (DATE[2:], TITLE, SLUG, DATE, TIME, TAGS)\n",
    "\n",
    "    print tmplt\n",
    "\n",
    "    if doit:\n",
    "        import os\n",
    "        print TITLE, TAGS\n",
    "        cmd = 'cd ..; nikola new_post --title=\"%s\" --tags=\"%s\"' % (TIMEDTITLE, TAGS)\n",
    "        print cmd\n",
    "        os.system(cmd)\n",
    "        f = file(SLUG + '.rst', 'w')\n",
    "        f.write(tmplt + pagerst)\n",
    "        f.close()\n",
    "    else:\n",
    "        print tmplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## updating dates to iso8601 : ipython notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob, os, shutil\n",
    "from nikola import utils\n",
    "\n",
    "for fname in glob.glob(\"posts/14*.ipynb\"):\n",
    "    ROOT, FILE = os.path.split(fname)\n",
    "    SLUG = 'posts/' + FILE.replace('.ipynb', '.meta')\n",
    "    FILE_new = 'posts/20' + FILE\n",
    "    SLUG_new = 'posts/20' + FILE.replace('.ipynb', '.meta')\n",
    "    print(SLUG)\n",
    "    meta = ''\n",
    "    with open(SLUG, 'r') as f: \n",
    "        for line in f.readlines():\n",
    "            meta += line.replace(' 14-', ' 2014-')\n",
    "    print(FILE_new, SLUG_new)\n",
    "    print(meta)\n",
    "    if True:\n",
    "        with open(SLUG_new, 'w') as f: f.write(meta)\n",
    "        shutil.copy( 'posts/' + FILE, FILE_new)\n",
    "        os.remove('posts/' + FILE)\n",
    "        os.remove(SLUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## updating dates to iso8601 : other posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import glob, os, shutil\n",
    "from nikola import utils\n",
    "\n",
    "for YEAR in [\"10\", \"11\", \"12\", \"13\", \"14\"]:\n",
    "    for fname in glob.glob(\"posts/\"+ YEAR + \"-*.txt\"):\n",
    "        ROOT, FILE = os.path.split(fname)\n",
    "        FILE_new = 'posts/20' + FILE\n",
    "        print(FILE_new)\n",
    "        if True:\n",
    "            shutil.copy( 'posts/' + FILE, FILE_new)\n",
    "            os.remove('posts/' + FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob, os, shutil\n",
    "from nikola import utils\n",
    "\n",
    "for ext in [\"*.txt\", \"*.rst\"]:\n",
    "    for YEAR in [\"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"]:\n",
    "        for fname in glob.glob(\"posts/20\"+ YEAR + ext):\n",
    "            ROOT, FILE = os.path.split(fname)\n",
    "            post = ''\n",
    "            with open('posts/' + FILE, 'r') as f: \n",
    "                for line in f.readlines():\n",
    "                    line = line.replace(' '+ YEAR + '-', ' 20'+ YEAR + '-')\n",
    "                    for YEAR_ in [\"10\", \"11\", \"12\", \"13\", \"14\"]:\n",
    "                        line = line.replace('<'+ YEAR_ + '-', '<20'+ YEAR_ + '-')\n",
    "                    post += line\n",
    "            print(FILE)\n",
    "            if True:\n",
    "                with open('posts/' + FILE, 'w') as f: f.write(post)\n",
    "            else:\n",
    "                print(post)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deploying changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m.\u001b[m\u001b[m/       \u001b[34m..\u001b[m\u001b[m/      \u001b[34mposts\u001b[m\u001b[m/   \u001b[34mstories\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%ls -a "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%rm -fr .doit.db cache"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!nikola clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[32mmodified:   bootstrapPost.ipynb\u001b[m\n",
      "\t\u001b[32mmodified:   posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[36m.doit.db.db\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!ls -ltr files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - jupyter_contrib_nbextensions\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda               pkgs/main::conda-4.9.2-py38hecd8cb5_0 --> conda-forge::conda-4.9.2-py38h50d1736_0\n",
      "  openssl                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -c conda-forge jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning posts...........done!\n",
      ".  render_posts:timeline_changes\n",
      ".  render_posts:cache/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html\n",
      "\u001b[1;33m[2020-11-24 17:43:18] WARNING: traitlets: Config option `template_path` not recognized by `HTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?\u001b[0m\n",
      ".  render_sources:docs/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.ipynb\n",
      ".  render_taxonomies:docs/categories/blog.html\n",
      ".  render_taxonomies:docs/categories/open-science.html\n",
      ".  render_taxonomies:docs/categories/pandas.html\n",
      ".  render_taxonomies:docs/categories/python.html\n",
      ".  render_taxonomies:docs/index.html\n",
      ".  render_taxonomies:docs/archive.html\n",
      ".  render_pages:docs/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html\n",
      ".  render_taxonomies:docs/rss.xml\n",
      ".  render_taxonomies:docs/categories/blog.xml\n",
      ".  render_taxonomies:docs/categories/open-science.xml\n",
      ".  render_taxonomies:docs/categories/pandas.xml\n",
      ".  render_taxonomies:docs/categories/python.xml\n",
      ".  sitemap:docs/sitemap.xml\n",
      ".  sitemap:docs/sitemapindex.xml\n"
     ]
    }
   ],
   "source": [
    "!nikola build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: posts/__temp__.mp4: No such file or directory\n",
      "rm: posts/debug.log: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%rm posts/__temp__.mp4 \tposts/debug.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning posts...........done!\n",
      "\u001b[1m[2020-11-24 17:46:46] INFO: deploy: => preset 'default'\u001b[0m\n",
      "\u001b[1m[2020-11-24 17:46:46] INFO: deploy: ==> git add posts/* docs/* files/*\u001b[0m\n",
      "\u001b[1m[2020-11-24 17:46:46] INFO: deploy: ==> git commit -am' updating site'\u001b[0m\n",
      "[master 6c1fc3d]  updating site\n",
      " 11 files changed, 2791 insertions(+), 5023 deletions(-)\n",
      " rewrite bootstrapPost.ipynb (83%)\n",
      "\u001b[1m[2020-11-24 17:46:46] INFO: deploy: ==> git push\u001b[0m\n",
      "Enumerating objects: 31, done.\n",
      "Counting objects: 100% (31/31), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (16/16), done.\n",
      "Writing objects: 100% (16/16), 2.75 KiB | 2.75 MiB/s, done.\n",
      "Total 16 (delta 15), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (15/15), completed with 15 local objects.\u001b[K\n",
      "To https://github.com/laurentperrinet/sciblog.git\n",
      "   8ac5278..6c1fc3d  master -> master\n",
      "\u001b[1m[2020-11-24 17:46:51] INFO: deploy: Successful deployment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!nikola deploy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "time.sleep(3600*0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning posts...........done!\n",
      ".  render_taxonomies:docs/index.html\n",
      "Scanning posts...........done!\n",
      "\u001b[1m[2020-11-24 17:50:11] INFO: deploy: => preset 'default'\u001b[0m\n",
      "\u001b[1m[2020-11-24 17:50:11] INFO: deploy: ==> git add posts/* docs/* files/*\u001b[0m\n",
      "\u001b[1m[2020-11-24 17:50:11] INFO: deploy: ==> git commit -am' updating site'\u001b[0m\n",
      "[master 180a0f7]  updating site\n",
      " 1 file changed, 59 insertions(+), 7 deletions(-)\n",
      "\u001b[1m[2020-11-24 17:50:11] INFO: deploy: ==> git push\u001b[0m\n",
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 808 bytes | 808.00 KiB/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/laurentperrinet/sciblog.git\n",
      "   6c1fc3d..180a0f7  master -> master\n",
      "\u001b[1m[2020-11-24 17:50:15] INFO: deploy: Successful deployment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!nikola build ; nikola deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[36m.doit.db.db\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning posts...........done!\n",
      ".  render_taxonomies:docs/index.html\n",
      "Scanning posts...........done!\n",
      "\u001b[1m[2020-11-24 18:26:14] INFO: deploy: => preset 'default'\u001b[0m\n",
      "\u001b[1m[2020-11-24 18:26:14] INFO: deploy: ==> git add posts/* docs/* files/*\u001b[0m\n",
      "\u001b[1m[2020-11-24 18:26:14] INFO: deploy: ==> git commit -am' updating site'\u001b[0m\n",
      "[master bc482f1]  updating site\n",
      " 1 file changed, 21 insertions(+), 21 deletions(-)\n",
      "\u001b[1m[2020-11-24 18:26:14] INFO: deploy: ==> git push\u001b[0m\n",
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 474 bytes | 474.00 KiB/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/laurentperrinet/sciblog.git\n",
      "   180a0f7..bc482f1  master -> master\n",
      "\u001b[1m[2020-11-24 18:26:18] INFO: deploy: Successful deployment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!nikola build ; nikola deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[32mmodified:   bootstrapPost.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[36m.doit.db.db\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status\n",
    "#!git add files/2018-11-13-testing-more-complex/trajectory_overlay*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapPost.ipynb:      \"\\t\\u001b[36m.doit.db.db\\u001b[m\\n\",\n",
      "bootstrapPost.ipynb:      \"\\t\\u001b[36m.doit.db.db\\u001b[m\\n\",\n"
     ]
    }
   ],
   "source": [
    "!grep -R .doit.db.db \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master be50111]  new page\n",
      " 3 files changed, 211 insertions(+), 114 deletions(-)\n",
      " mode change 100755 => 100644 docs/posts/2015-11-17-elasticite-expansion-en-miroir-dynamique-dun-point-focal.ipynb\n",
      " mode change 100755 => 100644 posts/2015-11-17-elasticite-expansion-en-miroir-dynamique-dun-point-focal.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git commit -am' new page' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 4fa15d5]  working on page\n",
      " 2 files changed, 43580 insertions(+), 10096 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -am' working on page' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open https://laurentperrinet.github.io/sciblog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
