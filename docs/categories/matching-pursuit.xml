<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about Matching Pursuit)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/matching-pursuit.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2019 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Tue, 26 Feb 2019 21:43:43 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Designing a A0 poster using matplotlib</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Poster-GDR-Vision"&gt;Poster GDR Vision&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html#Poster-GDR-Vision"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This poster was presented in Lille at a vision workshop, check out &lt;a href="https://laurentperrinet.github.io/publication/perrinet-17-gdr"&gt;https://laurentperrinet.github.io/publication/perrinet-17-gdr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Apart the content (which is in French) which recaps some previous work inbetween art and science, this post demonstrates how to generate a A0 poster &lt;em&gt;programmatically&lt;/em&gt;. In particular, we will use matplotlib and some quickly forged functions to ease up the formatting.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html"&gt;Read more…&lt;/a&gt; (20 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>elasticite</category><category>ipython</category><category>Matching Pursuit</category><category>open-science</category><category>outreach</category><category>python</category><category>trames</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</guid><pubDate>Wed, 25 Oct 2017 12:05:23 GMT</pubDate></item><item><title>Improving calls to the LogGabor library</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-10-06-improving-calls-to-the-loggabor-library.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;To code image as edges, for instance in the &lt;code&gt;SparseEdges&lt;/code&gt; &lt;a href="https://github.com/bicv/SparseEdges"&gt;sparse coding scheme&lt;/a&gt;, we use a model of edges in images. A good model for these edges are &lt;a href="https://en.wikipedia.org/wiki/Log_Gabor_filter#Bi-dimensional_Log-Gabor_filter"&gt;bidimensional Log Gabor filter&lt;/a&gt;. This is implemented for instance in the &lt;code&gt;LogGabor&lt;/code&gt; library. The library was designed to be precise, but not particularly for efficiency. In order to improve its speed, we demonstrate here the use of a cache to avoid redundant computations.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-10-06-improving-calls-to-the-loggabor-library.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>ipython</category><category>learning</category><category>LogGabor</category><category>Matching Pursuit</category><category>numpy</category><category>python</category><category>SLIP</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-10-06-improving-calls-to-the-loggabor-library.html</guid><pubDate>Fri, 06 Oct 2017 09:04:04 GMT</pubDate></item><item><title>A hitchhiker guide to Matching Pursuit</title><link>https://laurentperrinet.github.io/sciblog/posts/2015-05-22-a-hitchhiker-guide-to-matching-pursuit.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;figure&gt;&lt;img src="https://laurentperrinet.github.io/sciblog/files/2015-05-22-a-hitchhiker-guide-to-matching-pursuit/6370387703_5e718ea681_q_d.jpg"&gt;&lt;/figure&gt; &lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The Matching Pursuit algorithm is popular in signal processing and applies well to digital images.&lt;/p&gt;
&lt;p&gt;I have contributed a &lt;a href="https://github.com/bicv/SparseEdges"&gt;python implementation&lt;/a&gt; and we will show here how we may use that for extracting a sparse set of edges from an image.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;video controls autoplay loop src="https://laurentperrinet.github.io/sciblog/files/2015-05-22-a-hitchhiker-guide-to-matching-pursuit/MPtutorial_rec.mp4" width="61.8%/"&gt; &lt;/video&gt;&lt;/center&gt;
&lt;br&gt;

&lt;ul&gt;
&lt;li&gt;this will be exposed in the following book chapter (see also &lt;a href="https://laurentperrinet.github.io/publication/perrinet-15-bicv"&gt;https://laurentperrinet.github.io/publication/perrinet-15-bicv&lt;/a&gt; ), to be published by the end of this year:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nc"&gt;@inbook&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nl"&gt;Perrinet15bicv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;title&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;{Sparse models}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;author&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;{Perrinet, Laurent U.}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;booktitle&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;{Biologically-inspired Computer Vision}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;chapter&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;{13}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;editor&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;{Keil, Matthias and Crist\'{o}bal, Gabriel and Perrinet, Laurent U.}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;publisher&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;{Wiley, New-York}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;year&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;{2015}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2015-05-22-a-hitchhiker-guide-to-matching-pursuit.html"&gt;Read more…&lt;/a&gt; (32 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>bicv</category><category>LogGabor</category><category>Matching Pursuit</category><category>motionclouds</category><category>SparseEdges</category><guid>https://laurentperrinet.github.io/sciblog/posts/2015-05-22-a-hitchhiker-guide-to-matching-pursuit.html</guid><pubDate>Fri, 22 May 2015 08:59:33 GMT</pubDate></item></channel></rss>