<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about neural)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/neural.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2019 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Thu, 26 Sep 2019 17:34:01 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>2019-10-07 Neurostories: videos of my talk</title><link>https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Blah blah blah&lt;/p&gt;
&lt;p&gt;Emphasis, aka italics, with &lt;em&gt;asterisks&lt;/em&gt; or &lt;em&gt;underscores&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Strong emphasis, aka bold, with &lt;strong&gt;asterisks&lt;/strong&gt; or &lt;strong&gt;underscores&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Combined emphasis with &lt;strong&gt;asterisks and &lt;em&gt;underscores&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Strikethrough uses two tildes. &lt;del&gt;Scratch this.&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.google.com"&gt;I'm an inline-style link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.google.com" title="Google's Homepage"&gt;I'm an inline-style link with title&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.mozilla.org"&gt;I'm a reference-style link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/blob/master/LICENSE"&gt;I'm a relative reference to a repository file&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://slashdot.org"&gt;You can use numbers for reference-style link definitions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Or leave it empty and use the &lt;a href="http://www.reddit.com"&gt;link text itself&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;URLs and URLs in angle brackets will automatically get turned into links. 
&lt;a href="http://www.example.com"&gt;http://www.example.com&lt;/a&gt; or &lt;a href="http://www.example.com"&gt;http://www.example.com&lt;/a&gt; and sometimes 
example.com (but not on Github, for example).&lt;/p&gt;
&lt;p&gt;Some text to show that the reference links can follow later.&lt;/p&gt;
&lt;p&gt;Here's our logo (hover to see the title text):&lt;/p&gt;
&lt;p&gt;Inline-style: 
&lt;img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"&gt;&lt;/p&gt;
&lt;p&gt;Reference-style: 
&lt;img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"&gt;&lt;/p&gt;
&lt;p&gt;Inline &lt;code&gt;code&lt;/code&gt; has &lt;code&gt;back-ticks around&lt;/code&gt; it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"JavaScript syntax highlighting"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nx"&gt;alert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Python syntax highlighting"&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre&gt;&lt;code&gt;No language indicated, so no syntax highlighting. 
But let's throw in a &amp;lt;b&amp;gt;tag&amp;lt;/b&amp;gt;.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Colons can be used to align columns.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Tables&lt;/th&gt;
&lt;th style="text-align:center"&gt;Are&lt;/th&gt;
&lt;th style="text-align:right"&gt;Cool&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;col 3 is&lt;/td&gt;
&lt;td style="text-align:center"&gt;right-aligned&lt;/td&gt;
&lt;td style="text-align:right"&gt;$1600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;col 2 is&lt;/td&gt;
&lt;td style="text-align:center"&gt;centered&lt;/td&gt;
&lt;td style="text-align:right"&gt;$12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;zebra stripes&lt;/td&gt;
&lt;td style="text-align:center"&gt;are neat&lt;/td&gt;
&lt;td style="text-align:right"&gt;$1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There must be at least 3 dashes separating each header cell.
The outer pipes (|) are optional, and you don't need to make the 
raw Markdown line up prettily. You can also use inline Markdown.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Markdown&lt;/th&gt;
&lt;th&gt;Less&lt;/th&gt;
&lt;th&gt;Pretty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;Still&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;renders&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;nicely&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;&lt;p&gt;Blockquotes are very handy in email to emulate reply text.
This line is part of the same quote.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Quote break.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can &lt;em&gt;put&lt;/em&gt; &lt;strong&gt;Markdown&lt;/strong&gt; into a blockquote.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Free Energy</category><category>grand-public</category><category>moviepy</category><category>neural</category><category>outreach</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html</guid><pubDate>Thu, 26 Sep 2019 14:29:36 GMT</pubDate></item><item><title>Mainen &amp; Sejnowski, 1995</title><link>https://laurentperrinet.github.io/sciblog/posts/2019-05-28_MainenSejnowski1995.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this notebook, we will go from the learning numpy and matplotlib to our first neural simulator. As a case study, we will use the work from &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.8560&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Mainen &amp;amp; Sejnowski (1995)&lt;/a&gt;. The rest of this post is in french.&lt;/p&gt;
&lt;p&gt;Le but ici de cette première tache est de créer un "raster plot" qui montre la reproducibilité d'un train de spike avec des répétitions du même stimulus. E, particulier, nous allons essayer de répliquer la figure 1 de &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.8560&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Mainen &amp;amp; Sejnowski (1995)&lt;/a&gt;. Travail fait en collaboration avec les étudiants du L3 Sciences et Humanités Vision Lumière Couleurs d'AMU (Benjamin Chassagne, Romane Renou, Hassina Bendrer, Giulia Danielou)&lt;/p&gt;
&lt;p&gt;Ce notebook a été élaboré lors d'un TP dans le cadre de la &lt;a href="https://licencesh.hypotheses.org/"&gt;licence Sciences &amp;amp; Humanités&lt;/a&gt;.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2019-05-28_MainenSejnowski1995.html"&gt;Read more…&lt;/a&gt; (18 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>neural</category><category>open-science</category><category>pynn</category><guid>https://laurentperrinet.github.io/sciblog/posts/2019-05-28_MainenSejnowski1995.html</guid><pubDate>Tue, 28 May 2019 08:06:52 GMT</pubDate></item><item><title>Origins of the Von Mises distribution</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-12-23-origins-of-the-von-mises-distribution.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to check if the &lt;a href="https://en.wikipedia.org/wiki/Von_Mises_distribution"&gt;Von Mises distribution&lt;/a&gt; is the &lt;em&gt;a priori&lt;/em&gt; choice to make when handling polar coordinates.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-12-23-origins-of-the-von-mises-distribution.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>math</category><category>neural</category><category>orientation</category><category>sparse</category><category>v1</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-12-23-origins-of-the-von-mises-distribution.html</guid><pubDate>Sun, 23 Dec 2018 19:31:22 GMT</pubDate></item><item><title>Statistics of the natural input to a ring model</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-11-05-statistics-of-the-natural-input-to-a-ring-model.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;figure&gt;&lt;img src="https://laurentperrinet.github.io/sciblog/files/2018-11-05_Ring_input.png"&gt;&lt;/figure&gt; &lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;What does the input to a population of neurons in the primary visual cortex look like? In this post, we will try to have a feeling of the structure and statistics of the natural input to such a "ring" model.&lt;/p&gt;
&lt;p&gt;This notebook explores this question using a retina-like temporal filtering and oriented Gabor-like filters. It produces this polar plot of the instantaneous energy in the different orientations for a natural movie :&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;video controls autoplay loop src="https://laurentperrinet.github.io/sciblog/files/2018-11-05_Ring_input.mp4" width="61.8%/"&gt; &lt;/video&gt;&lt;/center&gt;
&lt;br&gt;

&lt;p&gt;One observes different striking features in the structure of this input to populations of V1 neurons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;input is sparse: often, a few orientations dominate - the shape of these components (bandwidth) seem to be similar,&lt;/li&gt;
&lt;li&gt;there are many "switches": at some moments, the representations flips to another. This is due to cuts in the movie (changes from one scene to the other for instance). In a more realistic setting where we would add eye movements, these switches should also happen during saccades (but is there any knowledge of the occurence of the switch by the visual system?),&lt;/li&gt;
&lt;li&gt;between switches, there is some coherence in amplitude (a component will slowly change its energy) but also in time (a component is more likely to have a ghradually changing oriantation, for instance when the scene rotates).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This structure is specific to the structure of natural images and to the way they transform (translations, rotations, zooms due to the motion and deformation of visual objects). This is certainly incorporated as a "prior" information in the structure of the visual cortex. As to know how and where this is implemented is an open scientific question.&lt;/p&gt;
&lt;p&gt;This is joint work with &lt;a href="https://laurentperrinet.github.io/authors/hugo-ladret"&gt;Hugo Ladret&lt;/a&gt;.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-11-05-statistics-of-the-natural-input-to-a-ring-model.html"&gt;Read more…&lt;/a&gt; (597 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>LogGabor</category><category>machine-learning</category><category>motion</category><category>motionclouds</category><category>neural</category><category>numpy</category><category>orientation</category><category>psychophysics</category><category>v1</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-11-05-statistics-of-the-natural-input-to-a-ring-model.html</guid><pubDate>Mon, 05 Nov 2018 14:41:07 GMT</pubDate></item><item><title>extending datasets in pyTorch</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-09-07-extending-datasets-in-pytorch.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://pytorch.org"&gt;PyTorch&lt;/a&gt; is a great library for machine learning. You can in a few lines of codes retrieve a dataset, define your model, add a cost function and then train your model. It's quite magic to copy and paste code from the internet and get the &lt;a href="https://github.com/pytorch/examples/tree/master/mnist"&gt;LeNet network&lt;/a&gt; working in a few seconds to achieve more than 98% accuracy.&lt;/p&gt;
&lt;p&gt;However, it can be tedious sometimes to extend existing objects and here, I will manipulate some ways to define the right dataset for your application. In particular I will modify the call to a standard dataset (&lt;a href="https://pytorch.org/docs/stable/torchvision/datasets.html#mnist"&gt;MNIST&lt;/a&gt;) to place the characters at random places in a large image.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-09-07-extending-datasets-in-pytorch.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>deep-learning</category><category>ipython</category><category>learning</category><category>machine-learning</category><category>neural</category><category>numpy</category><category>open-science</category><category>python</category><category>pytorch</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-09-07-extending-datasets-in-pytorch.html</guid><pubDate>Fri, 07 Sep 2018 10:27:10 GMT</pubDate></item><item><title>predictive-coding of variable motion</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-12-21-predictive-coding-of-variable-motion.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In some recent modeling work:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Laurent Perrinet, Guillaume S. Masson. Motion-based prediction is sufficient to solve the aperture problem. Neural Computation, 24(10):2726--50, 2012 &lt;a href="https://laurentperrinet.github.io/publication/perrinet-12-pred"&gt;https://laurentperrinet.github.io/publication/perrinet-12-pred&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;we study the role of transport in modifying our perception of motion. Here, we test what happens when we change the amount of noise in the stimulus.&lt;/p&gt;
&lt;p&gt;In this script the predictive coding is done using the &lt;code&gt;MotionParticles&lt;/code&gt; package and for a &lt;a href="https://laurentperrinet.github.io/sciblog/posts/motion%20texture"&gt;http://motionclouds.invibe.net/&lt;/a&gt; within a disk aperture.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-12-21-predictive-coding-of-variable-motion.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>motion</category><category>neural</category><category>open-science</category><category>predictive coding</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-12-21-predictive-coding-of-variable-motion.html</guid><pubDate>Thu, 21 Dec 2017 05:58:24 GMT</pubDate></item><item><title>MEUL with a non-parametric homeostasis</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-11-07-meul-with-a-non-parametric-homeostasis.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this notebook, we will study how homeostasis (cooperation) may be an essential ingredient to this algorithm working on a winner-take-all basis (competition). This extension has been published as Perrinet, Neural Computation (2010) (see  &lt;a href="https://laurentperrinet.github.io/publication/perrinet-10-shl"&gt;https://laurentperrinet.github.io/publication/perrinet-10-shl&lt;/a&gt; ). Compared to other posts, such as this &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum.html"&gt;previous post&lt;/a&gt;, we improve the code to not depend on any parameter (namely the &lt;code&gt;C&lt;/code&gt;parameter of the rescaling function). For that, we will use a non-parametric approach based on the use of cumulative histograms.&lt;/p&gt;
&lt;p&gt;This is joint work with &lt;a href="https://laurentperrinet.github.io/authors/victor-boutin"&gt;Victor Boutin&lt;/a&gt; and &lt;a href="https://invibe.net/LaurentPerrinet/AngeloFrancisioni"&gt;Angelo Francisioni&lt;/a&gt;. See also the other posts on &lt;a href="https://laurentperrinet.github.io/sciblog/categories/learning.html"&gt;unsupervised learning&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-11-07-meul-with-a-non-parametric-homeostasis.html"&gt;Read more…&lt;/a&gt; (47 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>bicv</category><category>learning</category><category>neural</category><category>open-science</category><category>SHL_scripts</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-11-07-meul-with-a-non-parametric-homeostasis.html</guid><pubDate>Tue, 07 Nov 2017 14:13:04 GMT</pubDate></item><item><title>The fastest 2D convolution in the world</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Convolutions are essential components of any neural networks, image processing, computer vision ... but these are also a bottleneck in terms of computations... I will here benchmark different solutions using &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt; or &lt;code&gt;pytorch&lt;/code&gt;. This is work-in-progress, so that any suggestion is welcome, for instance on &lt;a href="https://dsp.stackexchange.com/questions/43953/looking-for-fastest-2d-convolution-in-python-on-a-cpu"&gt;StackExchange&lt;/a&gt; or in the comments below this post.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>behavior</category><category>ipython</category><category>learning</category><category>neural</category><category>numpy</category><category>open-science</category><category>outreach</category><category>python</category><category>tensorflow</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</guid><pubDate>Wed, 20 Sep 2017 09:13:10 GMT</pubDate></item><item><title>testing COMPs-fastPcum_scripted</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum_scripted.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this notebook, we will study how homeostasis (cooperation) may be an essential ingredient to this algorithm working on a winner-take-all basis (competition). This extension has been published as Perrinet, Neural Computation (2010) (see  &lt;a href="https://laurentperrinet.github.io/publication/perrinet-10-shl"&gt;https://laurentperrinet.github.io/publication/perrinet-10-shl&lt;/a&gt; ). Compared to the &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum.html"&gt;previous post&lt;/a&gt;, we integrated the faster code to &lt;a href="https://github.com/bicv/SHL_scripts"&gt;https://github.com/bicv/SHL_scripts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;See also the other posts on &lt;a href="https://laurentperrinet.github.io/sciblog/categories/learning.html"&gt;unsupervised learning&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;This is joint work with &lt;a href="https://laurentperrinet.github.io/authors/victor-boutin"&gt;Victor Boutin&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum_scripted.html"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>bicv</category><category>learning</category><category>neural</category><category>open-science</category><category>SHL_scripts</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum_scripted.html</guid><pubDate>Tue, 23 May 2017 14:13:15 GMT</pubDate></item><item><title>testing COMPs-fastPcum</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this notebook, we will study how homeostasis (cooperation) may be an essential ingredient to this algorithm working on a winner-take-all basis (competition). This extension has been published as Perrinet, Neural Computation (2010) (see  &lt;a href="https://laurentperrinet.github.io/publication/perrinet-10-shl"&gt;https://laurentperrinet.github.io/publication/perrinet-10-shl&lt;/a&gt; ). Compared to the &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-pcum.html"&gt;previous post&lt;/a&gt;, we optimize the code to be faster.&lt;/p&gt;
&lt;p&gt;See also the other posts on &lt;a href="https://laurentperrinet.github.io/sciblog/categories/learning.html"&gt;unsupervised learning&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;This is joint work with &lt;a href="https://laurentperrinet.github.io/authors/victor-boutin"&gt;Victor Boutin&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum.html"&gt;Read more…&lt;/a&gt; (52 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>bicv</category><category>learning</category><category>neural</category><category>open-science</category><category>SHL_scripts</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-03-29-testing-comps-fastpcum.html</guid><pubDate>Tue, 23 May 2017 14:13:04 GMT</pubDate></item></channel></rss>