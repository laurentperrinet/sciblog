<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about OBV1)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/obv1.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Tue, 19 Oct 2021 07:13:45 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Recruiting different population ratios in V1 using orientation components: defining a protocol</title><link>https://laurentperrinet.github.io/sciblog/posts/2014-12-10_orientation_protocol.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;A feature of MotionClouds is the ability to precisely tune the precision of information  following the principal axes. One which is particularly relevant for the primary visual cortical area of primates (area V1) is to tune the otirentation mean and bandwidth.&lt;/p&gt;
&lt;p&gt;This is part of a larger study to tune &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation.html"&gt;orientation bandwidth&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="summary-of-the-electro-physiology-protocol"&gt;summary of the electro-physiology protocol&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2014-12-10_orientation_protocol.html#summary-of-the-electro-physiology-protocol"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2014-12-10_orientation_protocol.html"&gt;Read more…&lt;/a&gt; (42 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>area-V1</category><category>experiment</category><category>motionclouds</category><category>OBV1</category><category>orientation</category><guid>https://laurentperrinet.github.io/sciblog/posts/2014-12-10_orientation_protocol.html</guid><pubDate>Wed, 10 Dec 2014 09:56:20 GMT</pubDate></item><item><title>Recruiting different population ratios in V1 using orientation components</title><link>https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;A feature of MotionClouds is the ability to precisely tune the precision of information  following the principal axes. One which is particularly relevant for the primary visual cortical area of primates (area V1) is to tune the orientation mean and bandwidth.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation.html"&gt;Read more…&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>area-V1</category><category>experiment</category><category>motionclouds</category><category>OBV1</category><category>orientation</category><guid>https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation.html</guid><pubDate>Mon, 10 Nov 2014 09:56:20 GMT</pubDate></item><item><title>Recruiting different population ratios in V1 using orientation components: a biphoton study</title><link>https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation_biphoton.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;A feature of MotionClouds is the ability to precisely tune the precision of information  following the principal axes. One which is particularly relevant for the primary visual cortical area of primates (area V1) is to tune the otirentation mean and bandwidth.&lt;/p&gt;
&lt;p&gt;To install the necessary libraries, check out &lt;a href="https://github.com/NeuralEnsemble/MotionClouds/blob/master/README.md"&gt;the documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="summary-of-the-biphoton-protocol"&gt;summary of the biphoton protocol&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation_biphoton.html#summary-of-the-biphoton-protocol"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;For the biphoton experiment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The refresh rate of the screen is 70Hz and stimulation for 5 times 1s, which makes 350 images.&lt;/li&gt;
&lt;li&gt;for the spatial frequency 0.125 cyc/deg is optimal (between 0.01 and 0.16).&lt;/li&gt;
&lt;li&gt;for the temporal frequency 2 cyc/sec is optimal (between 0.8 and 4 sic/sec), we manipulate $B_V$ to get a qualitative estimate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation_biphoton.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>area-V1</category><category>experiment</category><category>motionclouds</category><category>OBV1</category><category>orientation</category><guid>https://laurentperrinet.github.io/sciblog/posts/2014-11-10_orientation_biphoton.html</guid><pubDate>Mon, 10 Nov 2014 09:56:20 GMT</pubDate></item></channel></rss>