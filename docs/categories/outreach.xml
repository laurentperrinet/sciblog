<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about outreach)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/outreach.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2020 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Tue, 24 Nov 2020 19:18:43 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Colors of the sky</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Our sensorial environment contains multiple regularities which our brain uses to optimize its representation of the world: objects fall most of the time downwards, the nose is usually in the middle below the eyes, the &lt;em&gt;sky is blue&lt;/em&gt;... Concerning this last point, I wish here to illustrate the physical origins of this phenomenon and in particular the range of colors that you may observe in the sky.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>grand-public</category><category>motionclouds</category><category>numpy</category><category>open-science</category><category>outreach</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html</guid><pubDate>Sat, 04 Jul 2020 10:05:58 GMT</pubDate></item><item><title>Caustic (optics)</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-06-19-caustic-optics.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Caustics (&lt;a href="https://en.wikipedia.org/wiki/Caustic_(optics"&gt;wikipedia&lt;/a&gt;) are luminous patterns which are resulting from the superposition of smoothly deviated light rays. It is for instance the heart-shaped pattern in your cup of coffee which is formed as the rays of the sun are reflected on the cup's surface. It is also the wiggly pattern of light curves that you will see on the floor of a pool as the sun's light is &lt;em&gt;refracted&lt;/em&gt; at the surface of the water. Here, we simulate that particular physical phenomenon. Simply because they are mesmerizingly beautiful, but also as it is of interest in visual neuroscience. Indeed, it speaks to how images are formed (more on this later), hence how the brain may understand images.&lt;/p&gt;
&lt;p&gt;In this post, I will develop a simple formalism to generate such patterns, with the paradoxical result that it is &lt;em&gt;very&lt;/em&gt; simple to code yet generates patterns with great complexity, such as:&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://laurentperrinet.github.io/sciblog/files/2020-06-19_caustique/2020-06-19_caustique.gif" width="61.8%/"&gt; &lt;/center&gt;
&lt;br&gt;

&lt;p&gt;This is joint work with artist &lt;a href="https://laurentperrinet.github.io/authors/etienne-rey/"&gt;Etienne Rey&lt;/a&gt;, in which I especially follow the ideas put forward in the series &lt;a href="http://ondesparalleles.org/projets/turbulences/"&gt;Turbulence&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zenodo.org/badge/latestdoi/273226625"&gt;&lt;img src="https://zenodo.org/badge/273226625.svg" alt="DOI"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-06-19-caustic-optics.html"&gt;Read more…&lt;/a&gt; (39 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>elasticite</category><category>grand-public</category><category>motionclouds</category><category>numpy</category><category>open-science</category><category>outreach</category><category>v1</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-06-19-caustic-optics.html</guid><pubDate>Fri, 19 Jun 2020 08:01:02 GMT</pubDate></item><item><title>Neurostories: creating videos of the flash-lag effect</title><link>https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This page recollects some variations on the flash-lag effect... and the way to easily and programmmatically generate those movies of the illusion.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;a href="https://laurentperrinet.github.io/post/2019-10-07_neurostories"&gt;&lt;video controls autoplay loop src="https://laurentperrinet.github.io/sciblog/files/2019-09-30_clock.mp4" width="61.8%/"&gt;&lt;/video&gt;&lt;/a&gt; &lt;/center&gt;
&lt;br&gt;


&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html"&gt;Read more…&lt;/a&gt; (14 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Free Energy</category><category>grand-public</category><category>moviepy</category><category>neural</category><category>outreach</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html</guid><pubDate>Thu, 26 Sep 2019 14:29:36 GMT</pubDate></item><item><title>Designing a A0 poster using matplotlib</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Poster-GDR-Vision"&gt;Poster GDR Vision&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html#Poster-GDR-Vision"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This poster was presented in Lille at a vision workshop, check out &lt;a href="https://laurentperrinet.github.io/publication/perrinet-17-gdr"&gt;https://laurentperrinet.github.io/publication/perrinet-17-gdr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Apart the content (which is in French) which recaps some previous work inbetween art and science, this post demonstrates how to generate a A0 poster &lt;em&gt;programmatically&lt;/em&gt;. In particular, we will use matplotlib and some quickly forged functions to ease up the formatting.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html"&gt;Read more…&lt;/a&gt; (20 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>elasticite</category><category>ipython</category><category>Matching Pursuit</category><category>open-science</category><category>outreach</category><category>python</category><category>trames</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</guid><pubDate>Wed, 25 Oct 2017 12:05:23 GMT</pubDate></item><item><title>The fastest 2D convolution in the world</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Convolutions are essential components of any neural networks, image processing, computer vision ... but these are also a bottleneck in terms of computations... I will here benchmark different solutions using &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt; or &lt;code&gt;pytorch&lt;/code&gt;. This is work-in-progress, so that any suggestion is welcome, for instance on &lt;a href="https://dsp.stackexchange.com/questions/43953/looking-for-fastest-2d-convolution-in-python-on-a-cpu"&gt;StackExchange&lt;/a&gt; or in the comments below this post.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>behavior</category><category>ipython</category><category>learning</category><category>neural</category><category>numpy</category><category>open-science</category><category>outreach</category><category>python</category><category>tensorflow</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</guid><pubDate>Wed, 20 Sep 2017 09:13:10 GMT</pubDate></item><item><title>Le jeu de l'urne</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-06-15-le-jeu-de-lurne.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;figure&gt;&lt;img src="https://laurentperrinet.github.io/sciblog/files/2015-12-08_cours_neurocomp/figures/questions.png"&gt;&lt;/figure&gt; &lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Lors de la visite au laboratoire d'une brillante élève de seconde (salut Lena!), nous avons inventé ensemble un jeu: &lt;em&gt;le jeu de l'urne&lt;/em&gt;. Le principe est simple: il faut deviner la couleur de la balle qu'on tire d'une urne contenant autant de balles rouges que noires - et ceci le plus tôt possible. Plus précisément, les règles sont:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On a un ensemble de balles, la motié sont rouges, l'autre moitié noires (c'est donc un nombre pair de balles qu'on appelera $N$, disons $N=8$). &lt;/li&gt;
&lt;li&gt;Elles sont dans une urne opaque et donc on ne peut pas les voir à moins de les tirer une par une (sans remise dans l'urne). On peut tirer autant de balles qu'on veut pour les observer.&lt;/li&gt;
&lt;li&gt;Le but est de deviner la balle qu'on va tirer. Si on gagne (on a bien prédit la couleur), alors on gagne autant de points que le nombre de balles qui étaient dans l'urne au moment de la décision. Sinon on perd autant de points que l'on en aurait gagné! &lt;/li&gt;
&lt;li&gt;à long terme, la stratégie du jeu est de décider le meilleur moment où on est prêt à deviner la couleur de la balle qu'on va prendre et ainsi de gagner le plus de points possibles.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nous avons d'abord créé ce jeu grâce au language de programmation &lt;a href="//scratch.mit.edu"&gt;Scratch&lt;/a&gt; sur &lt;a href="https://scratch.mit.edu/projects/165806365/"&gt;https://scratch.mit.edu/projects/165806365/&lt;/a&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;iframe allowtransparency="true" width="485" height="402" src="//scratch.mit.edu/projects/embed/165806365/?autostart=false" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Ici, nous allons essayer de l'analyser plus finement.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-06-15-le-jeu-de-lurne.html"&gt;Read more…&lt;/a&gt; (37 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>behavior</category><category>learning</category><category>open-science</category><category>outreach</category><category>psychophysics</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-06-15-le-jeu-de-lurne.html</guid><pubDate>Thu, 15 Jun 2017 14:42:44 GMT</pubDate></item></channel></rss>