<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about outreach)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/outreach.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2022 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Thu, 21 Jul 2022 11:03:31 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Dreamachine</title><link>https://laurentperrinet.github.io/sciblog/posts/2022-01-30-dreamachine.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;It's at the &lt;a href="https://miam.org/"&gt;MIAM&lt;/a&gt; (Miam Musée International des Arts Modestes) in Sète, France, that I could for the first time experience really the &lt;a href="https://en.wikipedia.org/wiki/Dreamachine"&gt;Dreamachine&lt;/a&gt;. It's an optical system which consists of a central light which is periodically occluded by a rotating (cardboard?) cylinder.&lt;/p&gt;
&lt;p&gt;The magic of it is that the frequency of occlusion is around $12$ Hz, an important resonant state for sensory system. For the first time, I could really try it out at the MIAM - the important point being to close your lids and rest quiet while looking at the stroboscopic light source. Surprisingly, you see the emergence of "psychedelic patterns" (of course, less than in hippie's movies) yet of the order of the color pattern that may arise in &lt;a href="https://en.wikipedia.org/wiki/Fechner_color"&gt;Benham's Disk&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It's difficult to reproduce this pattern on a screen, yet it is still possible to give an &lt;em&gt;impression of it&lt;/em&gt;. The goal is here :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;to generate a complex visual stimulation flickering on average at $12$ Hz&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;to project it on a retinotopic space to maximise the "psychelic" effect&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://laurentperrinet.github.io/sciblog/files/2022-01-30-dreamachine/retino_alpha.gif" alt="retino_alpha"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2022-01-30-dreamachine.html"&gt;Read more…&lt;/a&gt; (16 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>blog</category><category>grand-public</category><category>motionclouds</category><category>outreach</category><category>python</category><category>space</category><category>v1</category><guid>https://laurentperrinet.github.io/sciblog/posts/2022-01-30-dreamachine.html</guid><pubDate>Sun, 30 Jan 2022 10:33:46 GMT</pubDate></item><item><title>Find a 8 in a forest of 9</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-12-01-find-a-8-in-a-forest-of-9.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to find one non-repeting pattern in an image. First, find the pattern, then second, compute correlation.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-12-01-find-a-8-in-a-forest-of-9.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>blog</category><category>grand-public</category><category>math</category><category>outreach</category><category>python</category><category>space</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-12-01-find-a-8-in-a-forest-of-9.html</guid><pubDate>Wed, 01 Dec 2021 20:30:16 GMT</pubDate></item><item><title>Triangulating stars on the night sky</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-12-01-triangulating-stars-on-the-night-sky.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In a previous notebook, I have shown properties of the &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-03-27-density-of-stars-on-the-surface-of-the-sky.html"&gt;distribution of stars in the sky&lt;/a&gt;. Here, I would like to use the existing database of stars' positions and display them as a triangulation&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-12-01-triangulating-stars-on-the-night-sky.html"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>blog</category><category>grand-public</category><category>outreach</category><category>python</category><category>space</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-12-01-triangulating-stars-on-the-night-sky.html</guid><pubDate>Wed, 01 Dec 2021 09:32:39 GMT</pubDate></item><item><title>Density of stars on the surface of the sky</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-03-27-density-of-stars-on-the-surface-of-the-sky.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://zenodo.org/badge/latestdoi/191391751"&gt;&lt;img src="https://zenodo.org/badge/191391751.svg" alt="DOI"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Looking at the night sky, the pattern of stars on the surface of the sky follows a familiar pattern. The Big Dipper, Cassiopeia, the Pleiades, or Orion are popular landmarks in the sky which we can immediatly recognize.&lt;/p&gt;
&lt;p&gt;Different civilisations labelled these patterns using names such as constellations in the western world. However, this pattern is often the result of pure chance. Stars from one constellation belong often to remote areas in the universe and they bear this familiarity only because we always saw them as such; the rate at which stars move is much shorter than the lifespan of humanity.&lt;/p&gt;
&lt;p&gt;I am curious here to study the density of stars as they appear on the surface of the sky. It is both a simple question yet a complex to formulate. Is there any generic principle that could be used to characterize their distribution? This is my attempt to answer the question&lt;/p&gt;
&lt;p&gt;&lt;a href="https://astronomy.stackexchange.com/questions/43147/density-of-stars-on-the-surface-of-the-sky"&gt;https://astronomy.stackexchange.com/questions/43147/density-of-stars-on-the-surface-of-the-sky&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(but also to make the formulation of the question clearer...). This is my answer:
&lt;/p&gt;&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-03-27-density-of-stars-on-the-surface-of-the-sky.html"&gt;Read more…&lt;/a&gt; (33 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>grand-public</category><category>math</category><category>moviepy</category><category>outreach</category><category>python</category><category>space</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-03-27-density-of-stars-on-the-surface-of-the-sky.html</guid><pubDate>Sat, 27 Mar 2021 13:06:52 GMT</pubDate></item><item><title>Time lapsing an orchid's flower</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to realize a time-lapse using a raspberry π and some python code and finally get this:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://github.com/laurentperrinet/TimeTeleScope/raw/main/videos/2021-02-17_TimeTeleScope.gif" alt=""&gt;&lt;/p&gt;
&lt;p&gt;(This was done over 10 days, with &lt;em&gt;almost&lt;/em&gt; each day an &lt;em&gt;irregular&lt;/em&gt; session the morning and one in the evening)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>grand-public</category><category>learning</category><category>moviepy</category><category>numpy</category><category>outreach</category><category>python</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html</guid><pubDate>Sun, 21 Feb 2021 19:57:52 GMT</pubDate></item><item><title>Colors of the sky</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Our sensorial environment contains multiple regularities which our brain uses to optimize its representation of the world: objects fall most of the time downwards, the nose is usually in the middle below the eyes, the &lt;em&gt;sky is blue&lt;/em&gt;... Concerning this last point, I wish here to illustrate the physical origins of this phenomenon and in particular the range of colors that you may observe in the sky.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>grand-public</category><category>math</category><category>motionclouds</category><category>numpy</category><category>open-science</category><category>outreach</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html</guid><pubDate>Sat, 04 Jul 2020 10:05:58 GMT</pubDate></item><item><title>Caustic (optics)</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-06-19-caustic-optics.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Caustics (&lt;a href="https://en.wikipedia.org/wiki/Caustic_%28optics%29"&gt;wikipedia&lt;/a&gt; are luminous patterns which are resulting from the superposition of smoothly deviated light rays. It is for instance the heart-shaped pattern in your cup of coffee which is formed as the rays of the sun are reflected on the cup's surface. It is also the wiggly pattern of light curves that you will see on the floor of a pool as the sun's light is &lt;em&gt;refracted&lt;/em&gt; at the surface of the water. Here, we simulate that particular physical phenomenon. Simply because they are mesmerizingly beautiful, but also as it is of interest in visual neuroscience. Indeed, it speaks to how images are formed (more on this later), hence how the brain may understand images.&lt;/p&gt;
&lt;p&gt;In this post, I will develop a simple formalism to generate such patterns, with the paradoxical result that it is &lt;em&gt;very&lt;/em&gt; simple to code yet generates patterns with great complexity, such as:&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="https://laurentperrinet.github.io/sciblog/files/2020-06-19_caustique/2020-06-19_caustique.gif" width="61.8%/"&gt; &lt;/center&gt;
&lt;br&gt;

&lt;p&gt;This is joint work with artist &lt;a href="https://laurentperrinet.github.io/authors/etienne-rey/"&gt;Etienne Rey&lt;/a&gt;, in which I especially follow the ideas put forward in the series &lt;a href="http://ondesparalleles.org/projets/turbulences/"&gt;Turbulence&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zenodo.org/badge/latestdoi/273226625"&gt;&lt;img src="https://zenodo.org/badge/273226625.svg" alt="DOI"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-06-19-caustic-optics.html"&gt;Read more…&lt;/a&gt; (39 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>elasticite</category><category>grand-public</category><category>math</category><category>motionclouds</category><category>numpy</category><category>open-science</category><category>outreach</category><category>v1</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-06-19-caustic-optics.html</guid><pubDate>Fri, 19 Jun 2020 08:01:02 GMT</pubDate></item><item><title>Neurostories: creating videos of the flash-lag effect</title><link>https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This page recollects some variations on the flash-lag effect... and the way to easily and programmmatically generate those movies of the illusion.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;a href="https://laurentperrinet.github.io/post/2019-10-07_neurostories"&gt;&lt;video controls autoplay loop src="https://laurentperrinet.github.io/sciblog/files/2019-09-30_clock.mp4" width="61.8%/"&gt;&lt;/video&gt;&lt;/a&gt; &lt;/center&gt;
&lt;br&gt;


&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html"&gt;Read more…&lt;/a&gt; (14 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>computational neuroscience</category><category>Free Energy</category><category>grand-public</category><category>moviepy</category><category>neural</category><category>outreach</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2019-10-07-neurostories-videos-of-my-talk.html</guid><pubDate>Thu, 26 Sep 2019 14:29:36 GMT</pubDate></item><item><title>Designing a A0 poster using matplotlib</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Poster-GDR-Vision"&gt;Poster GDR Vision&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html#Poster-GDR-Vision"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This poster was presented in Lille at a vision workshop, check out &lt;a href="https://laurentperrinet.github.io/publication/perrinet-17-gdr"&gt;https://laurentperrinet.github.io/publication/perrinet-17-gdr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Apart the content (which is in French) which recaps some previous work inbetween art and science, this post demonstrates how to generate a A0 poster &lt;em&gt;programmatically&lt;/em&gt;. In particular, we will use matplotlib and some quickly forged functions to ease up the formatting.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html"&gt;Read more…&lt;/a&gt; (20 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>elasticite</category><category>ipython</category><category>Matching Pursuit</category><category>open-science</category><category>outreach</category><category>python</category><category>trames</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</guid><pubDate>Wed, 25 Oct 2017 12:05:23 GMT</pubDate></item><item><title>The fastest 2D convolution in the world</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Convolutions are essential components of any neural networks, image processing, computer vision ... but these are also a bottleneck in terms of computations... I will here benchmark different solutions using &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt; or &lt;code&gt;pytorch&lt;/code&gt;. This is work-in-progress, so that any suggestion is welcome, for instance on &lt;a href="https://dsp.stackexchange.com/questions/43953/looking-for-fastest-2d-convolution-in-python-on-a-cpu"&gt;StackExchange&lt;/a&gt; or in the comments below this post.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>behavior</category><category>ipython</category><category>learning</category><category>neural</category><category>numpy</category><category>open-science</category><category>outreach</category><category>python</category><category>tensorflow</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</guid><pubDate>Wed, 20 Sep 2017 09:13:10 GMT</pubDate></item></channel></rss>