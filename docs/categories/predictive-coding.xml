<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about predictive coding)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/predictive-coding.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sun, 17 Oct 2021 21:27:59 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Predictive coding of variable motion</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-12-21-predictive-coding-of-variable-motion.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In some recent modeling work:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Laurent Perrinet, Guillaume S. Masson. Motion-based prediction is sufficient to solve the aperture problem. Neural Computation, 24(10):2726--50, 2012 &lt;a href="https://laurentperrinet.github.io/publication/perrinet-12-pred"&gt;https://laurentperrinet.github.io/publication/perrinet-12-pred&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;we study the role of transport in modifying our perception of motion. Here, we test what happens when we change the amount of noise in the stimulus.&lt;/p&gt;
&lt;p&gt;In this script the predictive coding is done using the &lt;code&gt;MotionParticles&lt;/code&gt; package and for a &lt;a href="https://laurentperrinet.github.io/sciblog/posts/motion%20texture"&gt;https://neuralensemble.github.io/MotionClouds/&lt;/a&gt; within a disk aperture.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-12-21-predictive-coding-of-variable-motion.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>motion</category><category>neural</category><category>open-science</category><category>predictive coding</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-12-21-predictive-coding-of-variable-motion.html</guid><pubDate>Thu, 21 Dec 2017 05:58:24 GMT</pubDate></item><item><title>Predictive coding of motion in an aperture</title><link>https://laurentperrinet.github.io/sciblog/posts/2016-07-16-predictive-coding-of-motion-in-an-aperture.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;After reading the paper &lt;a href="http://www.jneurosci.org/content/34/37/12601.full"&gt;Motion Direction Biases and Decoding in Human Visual Cortex&lt;/a&gt; by  Helena X. Wang, Elisha P. Merriam, Jeremy Freeman, and David J. Heeger (The Journal of Neuroscience, 10 September 2014, 34(37): 12601-12615; doi: 10.1523/JNEUROSCI.1034-14.2014), I was interested to test the hypothesis they raise in the discussion section :&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The aperture-inward bias in V1–V3 may reflect spatial interactions between visual motion signals along the path of motion (Raemaekers et al., 2009; Schellekens et al., 2013). Neural responses might have been suppressed when the stimulus could be predicted from the responses of neighboring neurons nearer the location of motion origin, a form of predictive coding (Rao and Ballard, 1999; Lee and Mumford, 2003). Under this hypothesis, spatial interactions between neurons depend on both stimulus motion direction and the neuron's relative RF locations, but the neurons themselves need not be direction selective. Perhaps consistent with this hypothesis, psychophysical sensitivity is enhanced at locations further along the path of motion than at motion origin (van Doorn and Koenderink, 1984; Verghese et al., 1999).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Concerning the origins of aperture-inward bias, I want to test an alternative possibility. In some recent modeling work:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Laurent Perrinet, Guillaume S. Masson. Motion-based prediction is sufficient to solve the aperture problem. Neural Computation, 24(10):2726--50, 2012 &lt;a href="https://laurentperrinet.github.io/publication/perrinet-12-pred"&gt;https://laurentperrinet.github.io/publication/perrinet-12-pred&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was surprised to observe a similar behavior: the trailing edge was exhibiting a stronger activation (i. e. higher precision revealed by a lower variance in this probabilistic model) while I would have thought intuitively the leading edge would be more informative. In retrospect, it made sense in a motion-based prediction algorithm as information from the leading edge may propagate in more directions (135° for a 45° bar) than in the trailing edge (45°, that is a factor of 3 here). While we made this prediction we did not have any evidence for it.&lt;/p&gt;
&lt;p&gt;In this script the predictive coding is done using the &lt;code&gt;MotionParticles&lt;/code&gt; package and for a &lt;a href="https://laurentperrinet.github.io/sciblog/posts/motion%20texture"&gt;https://neuralensemble.github.io/MotionClouds/&lt;/a&gt; within a disk aperture.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2016-07-16-predictive-coding-of-motion-in-an-aperture.html"&gt;Read more…&lt;/a&gt; (26 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>LogGabor</category><category>motion</category><category>motionclouds</category><category>neural</category><category>open-science</category><category>predictive coding</category><guid>https://laurentperrinet.github.io/sciblog/posts/2016-07-16-predictive-coding-of-motion-in-an-aperture.html</guid><pubDate>Sat, 16 Jul 2016 05:58:24 GMT</pubDate></item></channel></rss>