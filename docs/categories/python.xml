<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about python)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/python.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sun, 21 Feb 2021 20:05:34 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>2021-02-21 Time lapsing an orchid's flower</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Blah blah blah&lt;/p&gt;
&lt;p&gt;Emphasis, aka italics, with &lt;em&gt;asterisks&lt;/em&gt; or &lt;em&gt;underscores&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Strong emphasis, aka bold, with &lt;strong&gt;asterisks&lt;/strong&gt; or &lt;strong&gt;underscores&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Combined emphasis with &lt;strong&gt;asterisks and &lt;em&gt;underscores&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Strikethrough uses two tildes. &lt;del&gt;Scratch this.&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.google.com"&gt;I'm an inline-style link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.google.com" title="Google's Homepage"&gt;I'm an inline-style link with title&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.mozilla.org"&gt;I'm a reference-style link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/blob/master/LICENSE"&gt;I'm a relative reference to a repository file&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://slashdot.org"&gt;You can use numbers for reference-style link definitions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Or leave it empty and use the &lt;a href="http://www.reddit.com"&gt;link text itself&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;URLs and URLs in angle brackets will automatically get turned into links. 
&lt;a href="http://www.example.com"&gt;http://www.example.com&lt;/a&gt; or &lt;a href="http://www.example.com"&gt;http://www.example.com&lt;/a&gt; and sometimes 
example.com (but not on Github, for example).&lt;/p&gt;
&lt;p&gt;Some text to show that the reference links can follow later.&lt;/p&gt;
&lt;p&gt;Here's our logo (hover to see the title text):&lt;/p&gt;
&lt;p&gt;Inline-style: 
&lt;img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"&gt;&lt;/p&gt;
&lt;p&gt;Reference-style: 
&lt;img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"&gt;&lt;/p&gt;
&lt;p&gt;Inline &lt;code&gt;code&lt;/code&gt; has &lt;code&gt;back-ticks around&lt;/code&gt; it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"JavaScript syntax highlighting"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nx"&gt;alert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Python syntax highlighting"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre&gt;&lt;code&gt;No language indicated, so no syntax highlighting. 
But let's throw in a &amp;lt;b&amp;gt;tag&amp;lt;/b&amp;gt;.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Colons can be used to align columns.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Tables&lt;/th&gt;
&lt;th style="text-align:center"&gt;Are&lt;/th&gt;
&lt;th style="text-align:right"&gt;Cool&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;col 3 is&lt;/td&gt;
&lt;td style="text-align:center"&gt;right-aligned&lt;/td&gt;
&lt;td style="text-align:right"&gt;$1600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;col 2 is&lt;/td&gt;
&lt;td style="text-align:center"&gt;centered&lt;/td&gt;
&lt;td style="text-align:right"&gt;$12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;zebra stripes&lt;/td&gt;
&lt;td style="text-align:center"&gt;are neat&lt;/td&gt;
&lt;td style="text-align:right"&gt;$1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There must be at least 3 dashes separating each header cell.
The outer pipes (|) are optional, and you don't need to make the 
raw Markdown line up prettily. You can also use inline Markdown.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Markdown&lt;/th&gt;
&lt;th&gt;Less&lt;/th&gt;
&lt;th&gt;Pretty&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;Still&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;renders&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;nicely&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;&lt;p&gt;Blockquotes are very handy in email to emulate reply text.
This line is part of the same quote.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Quote break.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can &lt;em&gt;put&lt;/em&gt; &lt;strong&gt;Markdown&lt;/strong&gt; into a blockquote.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>grand-public</category><category>learning</category><category>moviepy</category><category>numpy</category><category>outreach</category><category>python</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html</guid><pubDate>Sun, 21 Feb 2021 19:57:52 GMT</pubDate></item><item><title>Kuramoto model</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-kuramoto-model.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to re-implement the &lt;a href="https://en.wikipedia.org/wiki/Kuramoto_model"&gt;Kuramoto model&lt;/a&gt;, following a lecture from &lt;a href="https://sites.google.com/site/cvjoanacabral/"&gt;Joana Cabral&lt;/a&gt; and the &lt;a href="https://drive.google.com/drive/folders/1UGee2uB9y0FLbftxIRx-89KFeA87RifC"&gt;code&lt;/a&gt; that is provided, but using python instead of matlab.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-01-08-kuramoto-model.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>learning</category><category>neural</category><category>python</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-kuramoto-model.html</guid><pubDate>Fri, 08 Jan 2021 13:42:21 GMT</pubDate></item><item><title>Generating second-order figures from texture</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-generating-second-order-figures-from-texture.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to use the &lt;a href="https://github.com/NeuralEnsemble/MotionClouds"&gt;MotionClouds&lt;/a&gt; library to generate figures with second-order contours, similar to those used in the &lt;a href="https://nin.nl/research/researchgroups/roelfsema-group/"&gt;P. Roelfsema's group&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-01-08-generating-second-order-figures-from-texture.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>motionclouds</category><category>orientation</category><category>python</category><category>v1</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-generating-second-order-figures-from-texture.html</guid><pubDate>Fri, 08 Jan 2021 10:54:45 GMT</pubDate></item><item><title>Extracting music from the screenshots of a Spotify playlist</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post I'll try to show how from a screenshot obtained from a software like Spotify you can programmatically extract the tracks of the songs as well as the artists, to finally download them from the Internet.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html"&gt;Read more…&lt;/a&gt; (134 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>open-science</category><category>pandas</category><category>python</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html</guid><pubDate>Tue, 24 Nov 2020 14:19:07 GMT</pubDate></item><item><title>extending datasets in pyTorch</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-09-07-extending-datasets-in-pytorch.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://pytorch.org"&gt;PyTorch&lt;/a&gt; is a great library for machine learning. You can in a few lines of codes retrieve a dataset, define your model, add a cost function and then train your model. It's quite magic to copy and paste code from the internet and get the &lt;a href="https://github.com/pytorch/examples/tree/master/mnist"&gt;LeNet network&lt;/a&gt; working in a few seconds to achieve more than 98% accuracy.&lt;/p&gt;
&lt;p&gt;However, it can be tedious sometimes to extend existing objects and here, I will manipulate some ways to define the right dataset for your application. In particular I will modify the call to a standard dataset (&lt;a href="https://pytorch.org/docs/stable/torchvision/datasets.html#mnist"&gt;MNIST&lt;/a&gt;) to place the characters at random places in a large image.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-09-07-extending-datasets-in-pytorch.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>deep-learning</category><category>ipython</category><category>learning</category><category>machine-learning</category><category>neural</category><category>numpy</category><category>open-science</category><category>python</category><category>pytorch</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-09-07-extending-datasets-in-pytorch.html</guid><pubDate>Fri, 07 Sep 2018 10:27:10 GMT</pubDate></item><item><title>generating an unique seed for a given filename</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-06-13-generating-an-unique-seed-for-a-given-filename.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;When creating large simulations, you may sometimes create unique identifiers for each of it. This is useful to cache intermediate results for instance. This is the main function of &lt;a href="https://en.wikipedia.org/wiki/Hash_function"&gt;hashes&lt;/a&gt;. We will here create a simple one-liner function to generate one.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-06-13-generating-an-unique-seed-for-a-given-filename.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>ipython</category><category>numpy</category><category>open-science</category><category>psychophysics</category><category>python</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-06-13-generating-an-unique-seed-for-a-given-filename.html</guid><pubDate>Wed, 13 Jun 2018 11:02:57 GMT</pubDate></item><item><title>Designing a A0 poster using matplotlib</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Poster-GDR-Vision"&gt;Poster GDR Vision&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html#Poster-GDR-Vision"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This poster was presented in Lille at a vision workshop, check out &lt;a href="https://laurentperrinet.github.io/publication/perrinet-17-gdr"&gt;https://laurentperrinet.github.io/publication/perrinet-17-gdr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Apart the content (which is in French) which recaps some previous work inbetween art and science, this post demonstrates how to generate a A0 poster &lt;em&gt;programmatically&lt;/em&gt;. In particular, we will use matplotlib and some quickly forged functions to ease up the formatting.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html"&gt;Read more…&lt;/a&gt; (20 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>elasticite</category><category>ipython</category><category>Matching Pursuit</category><category>open-science</category><category>outreach</category><category>python</category><category>trames</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-10-25-designing-a-a0-poster-using-matplotlib.html</guid><pubDate>Wed, 25 Oct 2017 12:05:23 GMT</pubDate></item><item><title>Improving calls to the LogGabor library</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-10-06-improving-calls-to-the-loggabor-library.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;To code image as edges, for instance in the &lt;code&gt;SparseEdges&lt;/code&gt; &lt;a href="https://github.com/bicv/SparseEdges"&gt;sparse coding scheme&lt;/a&gt;, we use a model of edges in images. A good model for these edges are &lt;a href="https://en.wikipedia.org/wiki/Log_Gabor_filter#Bi-dimensional_Log-Gabor_filter"&gt;bidimensional Log Gabor filter&lt;/a&gt;. This is implemented for instance in the &lt;code&gt;LogGabor&lt;/code&gt; library. The library was designed to be precise, but not particularly for efficiency. In order to improve its speed, we demonstrate here the use of a cache to avoid redundant computations.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-10-06-improving-calls-to-the-loggabor-library.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>ipython</category><category>learning</category><category>LogGabor</category><category>Matching Pursuit</category><category>numpy</category><category>python</category><category>SLIP</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-10-06-improving-calls-to-the-loggabor-library.html</guid><pubDate>Fri, 06 Oct 2017 09:04:04 GMT</pubDate></item><item><title>The fastest 2D convolution in the world</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Convolutions are essential components of any neural networks, image processing, computer vision ... but these are also a bottleneck in terms of computations... I will here benchmark different solutions using &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt; or &lt;code&gt;pytorch&lt;/code&gt;. This is work-in-progress, so that any suggestion is welcome, for instance on &lt;a href="https://dsp.stackexchange.com/questions/43953/looking-for-fastest-2d-convolution-in-python-on-a-cpu"&gt;StackExchange&lt;/a&gt; or in the comments below this post.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>behavior</category><category>ipython</category><category>learning</category><category>neural</category><category>numpy</category><category>open-science</category><category>outreach</category><category>python</category><category>tensorflow</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-09-20-the-fastest-2d-convolution-in-the-world.html</guid><pubDate>Wed, 20 Sep 2017 09:13:10 GMT</pubDate></item><item><title>Some basics around probabilities</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-03-09_probabilities.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="basics-of-probability-theory"&gt;basics of probability theory&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2017-03-09_probabilities.html#basics-of-probability-theory"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In the context of a &lt;a href="https://github.com/laurentperrinet/2018-03-26_cours-NeuroComp_FEP"&gt;course in Computational Neuroscience&lt;/a&gt;, I am teaching a basic introduction in &lt;a href="https://laurentperrinet.github.io/sciblog/files/2018-03-26_cours-NeuroComp_FEP.html"&gt;Probabilities, Bayes and the Free-energy principle&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let's learn to use probabilities in practice by generating some "synthetic data", that is by using the computer's number generator. 
2018-03-26_cours-NeuroComp_FEP&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-03-09_probabilities.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>ipython</category><category>learning</category><category>open-science</category><category>python</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-03-09_probabilities.html</guid><pubDate>Thu, 09 Mar 2017 10:41:27 GMT</pubDate></item></channel></rss>