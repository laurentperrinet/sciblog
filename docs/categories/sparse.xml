<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about sparse)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/sparse.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2023 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Wed, 27 Dec 2023 21:13:09 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Role of gamma correction in Sparse coding</title><link>https://laurentperrinet.github.io/sciblog/posts/2019-11-28-role-of-gamma-correction-in-sparse-coding.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I have previously shown a &lt;a href="https://github.com/bicv/SparseEdges"&gt;python implementation&lt;/a&gt; which allows for the extraction a sparse set of edges from an image. We were using the raw luminance as the input to the algorithm. What happens if you use &lt;a href="https://en.wikipedia.org/wiki/Gamma_correction"&gt;gamma correction&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;&lt;img alt="albert on gamma" src="https://laurentperrinet.github.io/sciblog/files/2015-05-22-a-hitchhiker-guide-to-matching-pursuit/gamma.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Results : for this particular image, we checked that using the luminance ($\gamma \approx 1$) is the correct choice. The outcome is that &lt;em&gt;gamma correction may improve coding, but only slightly&lt;/em&gt;. In the figure below, we plot as a function of gamma the final energy of the error and the perceptually relevant measure of &lt;a href="https://scikit-image.org/docs/dev/auto_examples/transform/plot_ssim.html"&gt;structural simailarity&lt;/a&gt; :&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="albert on gamma" src="https://laurentperrinet.github.io/sciblog/files/2015-05-22-a-hitchhiker-guide-to-matching-pursuit/gamma_results.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;This may not be the case for other types of images which would justify an image-by-image local gain control.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;more information on sparse coding is exposed in the following book chapter (see also &lt;a href="https://laurentperrinet.github.io/publication/perrinet-15-bicv"&gt;https://laurentperrinet.github.io/publication/perrinet-15-bicv&lt;/a&gt; ):&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nc"&gt;@inbook&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nl"&gt;Perrinet15bicv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;title&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;{Sparse models}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;author&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;{Perrinet, Laurent U.}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;booktitle&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;{Biologically-inspired Computer Vision}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;chapter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;{13}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;editor&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;{Keil, Matthias and Crist\'{o}bal, Gabriel and Perrinet, Laurent U.}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;publisher&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;{Wiley, New-York}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;year&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;{2015}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2019-11-28-role-of-gamma-correction-in-sparse-coding.html"&gt;Read more…&lt;/a&gt; (9 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>LogGabor</category><category>machine-learning</category><category>orientation</category><category>SLIP</category><category>sparse</category><guid>https://laurentperrinet.github.io/sciblog/posts/2019-11-28-role-of-gamma-correction-in-sparse-coding.html</guid><pubDate>Thu, 28 Nov 2019 11:46:24 GMT</pubDate></item><item><title>Origins of the Von Mises distribution</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-12-23-origins-of-the-von-mises-distribution.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to check if the &lt;a href="https://en.wikipedia.org/wiki/Von_Mises_distribution"&gt;Von Mises distribution&lt;/a&gt; is the &lt;em&gt;a priori&lt;/em&gt; choice to make when handling polar coordinates.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-12-23-origins-of-the-von-mises-distribution.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>math</category><category>neural</category><category>orientation</category><category>sparse</category><category>v1</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-12-23-origins-of-the-von-mises-distribution.html</guid><pubDate>Sun, 23 Dec 2018 19:31:22 GMT</pubDate></item><item><title>Sparse coding of large images</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-12-13-sparse-coding-using-fista.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post we would try to show how one could infer the sparse representation of an image knowing an appropriate generative model for its synthesis. We will start by a linear inversion (pseudo-inverse deconvolution), and then move to a gradient descent algorithm. Finally, we will implement a convolutional version of the iterative shrinkage thresholding algorithm (ISTA) and its fast version, the FISTA.&lt;/p&gt;
&lt;p&gt;For computational efficiency, all convolutions will be implemented by a &lt;a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform"&gt;Fast Fourier Tansform&lt;/a&gt;, so that a standard convolution will be mathematically exactly similar. We will benchmark this on a realistic image size of $512 \times 512$ giving some timing results on a standard laptop.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-12-13-sparse-coding-using-fista.html"&gt;Read more…&lt;/a&gt; (795 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>computational neuroscience</category><category>learning</category><category>Matching Pursuit</category><category>math</category><category>neural</category><category>sparse</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-12-13-sparse-coding-using-fista.html</guid><pubDate>Thu, 13 Dec 2018 09:53:03 GMT</pubDate></item><item><title>Computing sparseness of natural images with retina-like RFs</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-11-21_retina_sparseness.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;load_ext&lt;/span&gt; autoreload
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;autoreload&lt;/span&gt; 2
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="SparseEdges-:-computing-sparseness-of-natural-images-with-retina-like-RFs"&gt;SparseEdges : computing sparseness of natural images with retina-like RFs&lt;a class="anchor-link" href="https://laurentperrinet.github.io/sciblog/posts/2017-11-21_retina_sparseness.html#SparseEdges-:-computing-sparseness-of-natural-images-with-retina-like-RFs"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Natural images follow statistics inherited by the structure of our physical (visual) environment. In particular, a prominent facet of this structure is that images can be described by a relatively sparse number of features. To investigate the role of this sparseness in the efficiency of the neural code, we designed a new class of random textured stimuli with a controlled sparseness value inspired by measurements of natural images. Then, we tested the impact of this sparseness parameter on the firing pattern observed in a population of retinal ganglion cells recorded ex vivo in the retina of a rodent, the Octodon degus. These recordings showed in particular that the reliability of spike timings varies with respect to the sparseness with globally a similar trend than the distribution of sparseness statistics observed in natural images. These results suggest that the code represented in the spike pattern of ganglion cells may adapt to this aspect of the statistics of natural images.&lt;/p&gt;
&lt;p&gt;&lt;img alt="statistics of natural images" src="https://laurentperrinet.github.io/publication/ravello-16-droplets/retina.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-11-21_retina_sparseness.html"&gt;Read more…&lt;/a&gt; (28 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>computational neuroscience</category><category>motionclouds</category><category>python</category><category>retina</category><category>sparse</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-11-21_retina_sparseness.html</guid><pubDate>Tue, 21 Nov 2017 09:56:27 GMT</pubDate></item><item><title>Bogacz (2017) A tutorial on free-energy</title><link>https://laurentperrinet.github.io/sciblog/posts/2017-01-15-bogacz-2017-a-tutorial-on-free-energy.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I enjoyed reading "A tutorial on the free-energy framework for modelling perception and learning" by &lt;em&gt;Rafal Bogacz&lt;/em&gt;, which is freely available &lt;a href="http://www.sciencedirect.com/science/article/pii/S0022249615000759"&gt;here&lt;/a&gt;. In particular, the author encourages to replicate the results in the paper. He is himself giving solutions in matlab, so I had to do the same in python all within a notebook...&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2017-01-15-bogacz-2017-a-tutorial-on-free-energy.html"&gt;Read more…&lt;/a&gt; (86 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>ipython</category><category>learning</category><category>open-science</category><category>python</category><category>sparse</category><guid>https://laurentperrinet.github.io/sciblog/posts/2017-01-15-bogacz-2017-a-tutorial-on-free-energy.html</guid><pubDate>Sun, 15 Jan 2017 20:41:27 GMT</pubDate></item></channel></rss>