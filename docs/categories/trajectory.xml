<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook (Posts about trajectory)</title><link>https://laurentperrinet.github.io/sciblog/</link><description></description><atom:link href="https://laurentperrinet.github.io/sciblog/categories/trajectory.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2024 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Tue, 06 Aug 2024 14:49:05 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Embedding a trajectory in noise</title><link>https://laurentperrinet.github.io/sciblog/posts/2018-11-13-testing-more-complex-trajectories.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Motion detection has many functions, one of which is the potential localization of the biomimetic camouflage seen in this &lt;a href="https://twitter.com/CoenCagli_Lab/status/1168565787818385408"&gt;video&lt;/a&gt;. Can we test this in the lab by using synthetic textures such as &lt;a href="https://neuralensemble.github.io/MotionClouds/"&gt;MotionClouds&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;However, by construction, MotionClouds have no spatial structure and it seems interesting to consider more complex trajectories. Following a &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-01-16-testing-more-complex-trajectories.html"&gt;previous post&lt;/a&gt;, we design a trajectory embedded in noise.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;&lt;table style="width:100%"&gt;&lt;tr&gt;&lt;td&gt;&lt;video autoplay="" controls="" loop="" src="https://laurentperrinet.github.io/sciblog/files/2018-11-13-testing-more-complex/trajectory_overlay.mp4" width="100%/"&gt;&lt;/video&gt;&lt;/td&gt;&lt;td&gt;&lt;video autoplay="" controls="" loop="" src="https://laurentperrinet.github.io/sciblog/files/2018-11-13-testing-more-complex/trajectory_overlay_reversed.mp4" width="100%/"&gt;&lt;/video&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;video autoplay="" controls="" loop="" src="https://laurentperrinet.github.io/sciblog/files/2018-11-13-testing-more-complex/trajectory_overlay_shuffled.mp4" width="100%/"&gt;&lt;/video&gt;&lt;/td&gt;&lt;td&gt;&lt;video autoplay="" controls="" loop="" src="https://laurentperrinet.github.io/sciblog/files/2018-11-13-testing-more-complex/trajectory_overlay_shuffled_reversed.mp4" width="100%/"&gt;&lt;/video&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Can you spot the motion ? from left to right or reversed ?&lt;/p&gt;
&lt;p&gt;(For a more controlled test, imagine you fixate on the top left corner of each movie.)&lt;/p&gt;
&lt;p&gt;(Upper row is coherent, lower row uncoherent / Left is &lt;code&gt;-&amp;gt;&lt;/code&gt; Right column is &lt;code&gt;&amp;lt;-&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2018-11-13-testing-more-complex-trajectories.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>code</category><category>motionclouds</category><category>trajectory</category><guid>https://laurentperrinet.github.io/sciblog/posts/2018-11-13-testing-more-complex-trajectories.html</guid><pubDate>Tue, 13 Nov 2018 09:43:46 GMT</pubDate></item></channel></rss>