{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous notebook, I have shown how to [fit a psychometric curve using pyTorch](https://laurentperrinet.github.io/sciblog/posts/2020-04-08-fitting-a-psychometric-curve-using-pytorch.html). Here, I would like to review some nice properies of the logistic regression model (WORK IN PROGRESS). \n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "Let's first initialize the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256 # number of factors\n",
    "n_classes = 10 # number of classes\n",
    "N_batch = 4\n",
    "seed = 1973 # release year of https://en.wikipedia.org/wiki/Ring_Ring_(ABBA_song)\n",
    "\n",
    "np.random.seed(seed)\n",
    "W = np.random.randn(N+1, n_classes) # FIXED design matrix\n",
    "\n",
    "def psychometric_function(W, factors):\n",
    "    print(W.shape, factors.shape)\n",
    "    logit = (factors @ W[:-1, :]) + W[-1, :]\n",
    "    return 1 / (1 + np.exp(-logit))\n",
    "\n",
    "def get_data(W, seed, N_batch):\n",
    "    N, n_classes = W.shape[0]-1, W.shape[1]\n",
    "    np.random.seed(seed)\n",
    "    factors = np.random.randn(N_batch, N)\n",
    "    p = psychometric_function(W, factors)\n",
    "    y = p > np.random.rand(N_batch, n_classes)  # generate data\n",
    "    \n",
    "    return factors, p, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = np.random.randn(N_batch, N)\n",
    "factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(factors@W[:-1, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((factors@W[:-1, :]) + W[-1, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 10) (4, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99953315e-01, 3.45805742e-04, 9.99999999e-01, 4.75663615e-10,\n",
       "        1.00000000e+00, 9.82830237e-01, 2.55754635e-09, 4.08280280e-01,\n",
       "        4.28969143e-08, 9.99999994e-01],\n",
       "       [1.10737661e-07, 8.51910182e-01, 2.73556933e-01, 9.99999999e-01,\n",
       "        5.29446551e-02, 1.00000000e+00, 6.10242975e-03, 9.99336308e-01,\n",
       "        1.00000000e+00, 9.29815468e-01],\n",
       "       [9.99999496e-01, 9.99936173e-01, 3.46135826e-07, 1.00000000e+00,\n",
       "        2.80007212e-04, 1.00000000e+00, 1.09061508e-07, 9.49790432e-04,\n",
       "        7.03708243e-07, 1.09295139e-04],\n",
       "       [1.00000000e+00, 9.99999846e-01, 1.00000000e+00, 9.99999968e-01,\n",
       "        1.33090647e-04, 1.00000000e+00, 5.67447527e-02, 9.81359607e-01,\n",
       "        9.99998653e-01, 9.99882309e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psychometric_function(W, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 10) (4, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4, 256), (4, 10), (4, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors, p, y = get_data(W, seed, N_batch)\n",
    "factors.shape, p.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([17.,  1.,  1.,  0.,  0.,  2.,  0.,  0.,  0., 19.]),\n",
       " array([1.10640081e-12, 1.00000000e-01, 2.00000000e-01, 3.00000000e-01,\n",
       "        4.00000000e-01, 5.00000000e-01, 6.00000000e-01, 7.00000000e-01,\n",
       "        8.00000000e-01, 9.00000000e-01, 1.00000000e+00]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p.ravel(), bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "torch.set_default_tensor_type(\"torch.DoubleTensor\") # -> torch.tensor([1.2, 3]).dtype = torch.float64\n",
    "# see https://sebastianraschka.com/faq/docs/pytorch-crossentropy.html#pytorch-loss-input-confusion-cheatsheet\n",
    "criterion = torch.nn.BCELoss(reduction=\"mean\") # loss divided by output size\n",
    "#criterion = torch.nn.NLLLoss(reduction=\"mean\") # loss divided by output size\n",
    "\n",
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    #torch.nn.Module -> Base class for all neural network modules\n",
    "    def __init__(self, N, n_classes, bias=True):\n",
    "        super(LogisticRegressionModel, self).__init__() \n",
    "        self.linear = torch.nn.Linear(N, n_classes, bias=bias)\n",
    "        # self.nl = torch.nn.LogSoftmax(n_classes)\n",
    "        self.nl = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, factors):\n",
    "        return self.nl(self.linear(factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 9 + 1\n",
    "batch_size = 256\n",
    "n_classes=10\n",
    "amsgrad = False # gives similar results\n",
    "amsgrad = True  # gives similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegressionModel(N, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = torch.randn(N_batch, N)\n",
    "outputs = logistic_model(factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data(factors, y, \n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,  # gamma=gamma,\n",
    "            num_epochs=num_epochs,\n",
    "            betas=betas,\n",
    "            verbose=False, **kwargs\n",
    "        ):\n",
    "\n",
    "    X, labels = torch.Tensor(factors[:, None]), torch.Tensor(y[:, None])\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(X, labels), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    N_batch = factors.shape[0]\n",
    "    N = factors.shape[1]\n",
    "    n_classes = y.shape[1]\n",
    "    logistic_model = LogisticRegressionModel(N, n_classes)\n",
    "    logistic_model = logistic_model.to(device)\n",
    "    logistic_model.train()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        logistic_model.parameters(), lr=learning_rate, betas=betas, amsgrad=amsgrad\n",
    "    )\n",
    "    for epoch in range(int(num_epochs)):\n",
    "        logistic_model.train()\n",
    "        losses = []\n",
    "        for X_, labels_ in loader:\n",
    "            X_, labels_ = X_.to(device), labels_.to(device)\n",
    "            outputs = logistic_model(X_)\n",
    "            loss = criterion(outputs, labels_)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if verbose and (epoch % (num_epochs // 32) == 0):\n",
    "            print(f\"Iteration: {epoch} - Loss: {np.mean(losses):.5f}\")\n",
    "\n",
    "    logistic_model.eval()\n",
    "    X, labels = torch.Tensor(factors[:, None]), torch.Tensor(y[:, None])\n",
    "    outputs = logistic_model(X)\n",
    "    loss = criterion(outputs, labels).item()\n",
    "    return logistic_model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 10) (10000, 256)\n",
      "Iteration: 0 - Loss: 0.51191\n",
      "Iteration: 16 - Loss: 0.11679\n",
      "Iteration: 32 - Loss: 0.09595\n",
      "Iteration: 48 - Loss: 0.08673\n",
      "Iteration: 64 - Loss: 0.08175\n",
      "Iteration: 80 - Loss: 0.07856\n",
      "Iteration: 96 - Loss: 0.07641\n",
      "Iteration: 112 - Loss: 0.07492\n",
      "Iteration: 128 - Loss: 0.07407\n",
      "Iteration: 144 - Loss: 0.07360\n",
      "Iteration: 160 - Loss: 0.07150\n"
     ]
    }
   ],
   "source": [
    "factors, p, y = get_data(W, seed=seed, N_batch=10000)\n",
    "logistic_model, loss = fit_data(factors, y, verbose=True)\n",
    "print(\"Final loss =\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "ax.plot(logistic_model.linear.bias.detach().numpy(), 'r')\n",
    "ax.plot(W[-1, :], 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.linear.weight.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_digit = 2\n",
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "ax.plot(W[:, i_digit], 'g--', lw=3)\n",
    "ax.plot(logistic_model.linear.weight[i_digit, :].detach().numpy(), 'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
