<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scientific logbook</title><link>https://laurentperrinet.github.io/sciblog/</link><description>

This is my scientific logbook.
Experiments happen here in an apparently random order,
most of the time with more questions than answers...
Do not hesitate to comment!
</description><atom:link href="https://laurentperrinet.github.io/sciblog/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:laurent.perrinet@univ-amu.fr"&gt;Laurent Perrinet&lt;/a&gt; 
&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/ar/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="http://i.creativecommons.org/l/by-nc-sa/2.5/ar/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Tue, 19 Oct 2021 06:32:28 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Modelling Ocean surface waves</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-09-11-modelling-ocean-surface-waves.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Trying to model Ocean surface waves, I have played using a &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2014-10-24_a-bit-of-fun-with-gravity-waves.html"&gt;linear superposition of sinusoids&lt;/a&gt; and also on the fact that &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2016-04-24_a-wave-going-backwards.html"&gt;phase speed (following a wave's crest) is twice as fast as group speed (following a group of waves)&lt;/a&gt;. Finally, I more recently used such generation of a model of the random superposition of waves to model the &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-06-19-caustic-optics.html"&gt;wigggling lines formed by the refraction (bendings of the trajectory of a ray at the interface between air and water) of light, called caustics&lt;/a&gt;...&lt;/p&gt;
&lt;p&gt;Observing real-life ocean waves instructed me that if a single wave is well approximated by a sinusoïd, each wave is qualitatively a bit different. Typical for these surface gravity waves are &lt;a href="https://en.wikipedia.org/wiki/Stokes_wave"&gt;the sharp crests and flat troughs&lt;/a&gt;. As a matter of fact, modelling ocean waves is on one side very useful (&lt;a href="https://en.wikipedia.org/wiki/Ocean_dynamics"&gt;Ocean dynamics&lt;/a&gt; and its impact on climate, modelling tides, tsunamis, diffraction in a bay to predict coastline evolution, ...) but quite demanding despite a &lt;a href="https://en.wikipedia.org/wiki/Airy_wave_theory"&gt;well known mathematical model&lt;/a&gt;. Starting with the Navier-Stokes equations to an incompressible fluid (water) in a gravitational field leads to &lt;a href="https://en.wikipedia.org/wiki/Luke%27s_variational_principle"&gt;Luke's variational principle&lt;/a&gt; in certain simplifying conditions. Further simplifications lead to the approximate solution given by Stokes which gives the following shape as the sum of different harmonics:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Stokes3_wave.svg/2880px-Stokes3_wave.svg.png" alt="Stokes wave(https://en.wikipedia.org/wiki/Stokes_wave)"&gt;&lt;/p&gt;
&lt;p&gt;This seems well enough at the moment and I will capture this shape in this notebook and notably if that applies to a random mixture of such waves...&lt;/p&gt;
&lt;p&gt;(WORK IN PROGRESS)&lt;/p&gt;
&lt;p&gt;The current situation is that these slutions seem to not fit what is displayed on the wikipedia page and that I do not spot the bug I may have introduced...&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-09-11-modelling-ocean-surface-waves.html"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>blog</category><category>elasticite</category><category>python</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-09-11-modelling-ocean-surface-waves.html</guid><pubDate>Sat, 11 Sep 2021 09:56:27 GMT</pubDate></item><item><title>Density of stars on the surface of the sky</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-03-27-density-of-stars-on-the-surface-of-the-sky.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://zenodo.org/badge/latestdoi/191391751"&gt;&lt;img src="https://zenodo.org/badge/191391751.svg" alt="DOI"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Looking at the night sky, the pattern of stars on the surface of the sky follows a familiar pattern. The Big Dipper, Cassiopeia, the Pleiades, or Orion are popular landmarks in the sky which we can immediatly recognize.&lt;/p&gt;
&lt;p&gt;Different civilisations labelled these patterns using names such as constellations in the western world. However, this pattern is often the result of pure chance. Stars from one constellation belong often to remote areas in the universe and they bear this familiarity only because we always saw them as such; the rate at which stars move is much shorter than the lifespan of humanity.&lt;/p&gt;
&lt;p&gt;I am curious here to study the density of stars as they appear on the surface of the sky. It is both a simple question yet a complex to formulate. Is there any generic principle that could be used to characterize their distribution? This is my attempt to answer the question&lt;/p&gt;
&lt;p&gt;&lt;a href="https://astronomy.stackexchange.com/questions/43147/density-of-stars-on-the-surface-of-the-sky"&gt;https://astronomy.stackexchange.com/questions/43147/density-of-stars-on-the-surface-of-the-sky&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(but also to make the formulation of the question clearer...). This is my answer:
&lt;/p&gt;&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-03-27-density-of-stars-on-the-surface-of-the-sky.html"&gt;Read more…&lt;/a&gt; (33 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>grand-public</category><category>moviepy</category><category>outreach</category><category>python</category><category>space</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-03-27-density-of-stars-on-the-surface-of-the-sky.html</guid><pubDate>Sat, 27 Mar 2021 13:06:52 GMT</pubDate></item><item><title>Time lapsing an orchid's flower</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to realize a time-lapse using a raspberry π and some python code and finally get this:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://github.com/laurentperrinet/TimeTeleScope/raw/main/videos/2021-02-17_TimeTeleScope.gif" alt=""&gt;&lt;/p&gt;
&lt;p&gt;(This was done over 10 days, with &lt;em&gt;almost&lt;/em&gt; each day an &lt;em&gt;irregular&lt;/em&gt; session the morning and one in the evening)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>grand-public</category><category>learning</category><category>moviepy</category><category>numpy</category><category>outreach</category><category>python</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-02-21-time-lapsing-an-orchids-flower.html</guid><pubDate>Sun, 21 Feb 2021 19:57:52 GMT</pubDate></item><item><title>Kuramoto model</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-kuramoto-model.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to re-implement the &lt;a href="https://en.wikipedia.org/wiki/Kuramoto_model"&gt;Kuramoto model&lt;/a&gt;, following a lecture from &lt;a href="https://sites.google.com/site/cvjoanacabral/"&gt;Joana Cabral&lt;/a&gt; and the &lt;a href="https://drive.google.com/drive/folders/1UGee2uB9y0FLbftxIRx-89KFeA87RifC"&gt;code&lt;/a&gt; that is provided, but using python instead of matlab.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-01-08-kuramoto-model.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>learning</category><category>neural</category><category>python</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-kuramoto-model.html</guid><pubDate>Fri, 08 Jan 2021 13:42:21 GMT</pubDate></item><item><title>Generating second-order figures from texture</title><link>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-generating-second-order-figures-from-texture.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to use the &lt;a href="https://github.com/NeuralEnsemble/MotionClouds"&gt;MotionClouds&lt;/a&gt; library to generate figures with second-order contours, similar to those used in the &lt;a href="https://nin.nl/research/researchgroups/roelfsema-group/"&gt;P. Roelfsema's group&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2021-01-08-generating-second-order-figures-from-texture.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>motionclouds</category><category>orientation</category><category>python</category><category>v1</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2021-01-08-generating-second-order-figures-from-texture.html</guid><pubDate>Fri, 08 Jan 2021 10:54:45 GMT</pubDate></item><item><title>Extracting music from the screenshots of a Spotify playlist</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post I'll try to show how from a screenshot obtained from a software like Spotify you can programmatically extract the tracks of the songs as well as the artists, to finally download them from the Internet.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html"&gt;Read more…&lt;/a&gt; (134 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blog</category><category>open-science</category><category>pandas</category><category>python</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-11-24-extracting-music-from-the-screenshots-of-a-spotify-playlist.html</guid><pubDate>Tue, 24 Nov 2020 14:19:07 GMT</pubDate></item><item><title>Fitting COVID data</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-10-10-fitting-covid-data.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I propose here a simple method to fit experimental data common to epidemiological spreads, such as the present COVID-19 pandemic, using the &lt;a href="https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution"&gt;inverse gaussian distribution&lt;/a&gt;. This follows the general incompregension of my answer to the question &lt;a href="https://stats.stackexchange.com/questions/455202/is-the-covid-19-pandemic-curve-a-gaussian-curve/456016#456016"&gt;Is the COVID-19 pandemic curve a Gaussian curve?&lt;/a&gt; on StackOverflow. My initial point is to say that a Gaussian is not adapted as it handles a distribution on real numbers, while such a curve (the variable being number of days) handles numbers on the half line. Inspired by the &lt;em&gt;excellent&lt;/em&gt; &lt;a href="https://core.ac.uk/display/141211187"&gt;A Theory of Reaction Time Distributions&lt;/a&gt; by Dr Fermin Moscoso del Prado Martin a constructive approach is to propose another distribution, such as the inverse Gaussian distribution.&lt;/p&gt;
&lt;p&gt;This notebook develops this same idea on real data and proves &lt;em&gt;numerically&lt;/em&gt; how bad the Gaussian fit is compared to the latter. Thinking about the importance of doing a proper inference in such a case, I conclude&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-10-10-fitting-covid-data.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>machine-learning</category><category>math</category><category>numpy</category><category>open-science</category><category>pandas</category><category>pytorch</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-10-10-fitting-covid-data.html</guid><pubDate>Sat, 10 Oct 2020 12:13:12 GMT</pubDate></item><item><title>Benchmarking CNNs</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-09-28-benchmarking-cnns.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Hi! I am  &lt;a href="https://github.com/JNJER"&gt;Jean-Nicolas Jérémie&lt;/a&gt; and the goal of this benchmark is to offer a comparison between differents pre-trained image recognition's networks based on the &lt;a href="http://image-net.org/"&gt;Imagenet&lt;/a&gt; dataset wich allows to work on naturals images for $1000$ labels. These different networks tested here are taken from the &lt;code&gt;torchvision.models&lt;/code&gt; library : &lt;code&gt;AlexNet&lt;/code&gt;, &lt;code&gt;VGG16&lt;/code&gt;, &lt;code&gt;MobileNetV2&lt;/code&gt; and &lt;code&gt;ResNet101&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Our use case is to measure the performance of a system which receives a sequence of images and has to make a decision as soon as possible, hence with &lt;code&gt;batch_size=1&lt;/code&gt;. Specifically, we wish also to compare different computing architectures such as CPUs, desktop GPUs or other more exotic platform such as the Jetson TX2 (experiment 1). Additionally, we will implement some image transformations as up/down-sampling (experiment 2) or transforming to grayscale (experiment 3) to quantify their influence on the accuracy and computation time of each network.&lt;/p&gt;
&lt;p&gt;In this notebook, I will use the &lt;a href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; library for running the networks and the &lt;a href="https://pandas.pydata.org/docs/getting_started/index.html"&gt;pandas&lt;/a&gt; library to collect and display the results. This notebook was done during a master 1 internship at the Neurosciences Institute of Timone (INT) under the supervision of &lt;a href="https://laurentperrinet.github.io/"&gt;Laurent PERRINET&lt;/a&gt;. It is curated in the following &lt;a href="https://github.com/JNJER/2020-06-26_fast_and_curious"&gt;github repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-09-28-benchmarking-cnns.html"&gt;Read more…&lt;/a&gt; (35 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>deep-learning</category><category>jupyter</category><category>machine-learning</category><category>open-science</category><category>pandas</category><category>pytorch</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-09-28-benchmarking-cnns.html</guid><pubDate>Mon, 28 Sep 2020 15:25:57 GMT</pubDate></item><item><title>nesting jupyter runs</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-08-09-nesting-jupyter-runs.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://jupyter.org/"&gt;Jupyter notebooks&lt;/a&gt; are a great way of sharing knowledge in science, art, programming. 
For instance, in a recent musing, I tried to programmatically determine the &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html"&gt;color of the sky&lt;/a&gt;. This renders as a web page, but is also a piece of &lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.ipynb"&gt;runnable code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As such, they are also great ways to store the knowledge that was acquired at a given time and that could be reusable. This may be considered as bad programming and may have downsides as described in that &lt;a href="https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/edit#slide=id.g362da58057_0_1"&gt;slides&lt;/a&gt; :&lt;/p&gt;
&lt;p&gt;&lt;a href="https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/edit#slide=id.g362da58057_0_1"&gt;&lt;img src="https://revolution-computing.typepad.com/.a/6a010534b1db25970b022ad3b0836c200b-800wi" alt="Joel Grus"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Recently, thanks to an answer to a &lt;a href="https://stackoverflow.com/questions/48067529/ipython-run-magic-n-switch-not-working"&gt;stack overflow question&lt;/a&gt;,  I found a way to overcome this by detecting if the caall to a notebook is made from the notebook itself or from a parent.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-08-09-nesting-jupyter-runs.html"&gt;Read more…&lt;/a&gt; (1861 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>ipython</category><category>jupyter</category><category>open-science</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-08-09-nesting-jupyter-runs.html</guid><pubDate>Sun, 09 Aug 2020 08:52:18 GMT</pubDate></item><item><title>Colors of the sky</title><link>https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html</link><dc:creator>Laurent Perrinet</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Our sensorial environment contains multiple regularities which our brain uses to optimize its representation of the world: objects fall most of the time downwards, the nose is usually in the middle below the eyes, the &lt;em&gt;sky is blue&lt;/em&gt;... Concerning this last point, I wish here to illustrate the physical origins of this phenomenon and in particular the range of colors that you may observe in the sky.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>art</category><category>grand-public</category><category>motionclouds</category><category>numpy</category><category>open-science</category><category>outreach</category><category>vision</category><guid>https://laurentperrinet.github.io/sciblog/posts/2020-07-04-colors-of-the-sky.html</guid><pubDate>Sat, 04 Jul 2020 10:05:58 GMT</pubDate></item></channel></rss>