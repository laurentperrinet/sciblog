{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a master's project in computational neuroscience, we adopted a quite novel workflow to go all the steps from the learning of the small steps to the wrtiting of the final thesis. Though we were flexible in our method during the 6 months of this work, a simple workflow emerged that I describe here.\n",
    "\n",
    "![Compiling a set of notebook to a LaTeX document.](../files/2016-06-26_thesis.png)\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "The project involved the modelling of a rather complex system involving the modelling of spiking neurons, studying the emerging states when they interact in populations. Of particular interest was the possibility to obtain what is called a \"balanced state\" which is relevant to model the brain. Finally, we modeled some realistic representation of the coding of orientation in what is called a \"ring model\". \n",
    "* As such, we had a hierarchy of problems to solve from the single neuron to the full network. The only solution was thus to take small steps and we were careful to create on a daily basis new notebooks reporting for these advances (pre-pended with the iso8601, for instance ``2016-03-02_FeedForward_comparing_ExpVSAlpha``). \n",
    "* To avoid the usual rush at the moment of handing over the thesis, another constraint that we adopted was that for every notebook, the first cell would describe what was done with possibly a visual figure. One huge advantage is that the student did not have to learn LaTeX, but only markdown.\n",
    "* In the end we had a bunch of notebooks that could just be \"compiled\" to produce a nice looking PDF file.\n",
    "\n",
    "Let's focus on how to do that. For those in a hurry, let's just say that it involves:\n",
    "* globing a set of relevant notebooks,\n",
    "* striping out what is not important and keep the important stuff,\n",
    "* concatenate all of these in one notebook,\n",
    "* convert that to a PDF using a latex template\n",
    "This is summarized in this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting thesis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile thesis.py\n",
    "name = 'thesis'\n",
    "\n",
    "import nbconvert\n",
    "import nbformat\n",
    "\n",
    "nb_list = []\n",
    "import glob\n",
    "for fname in glob.glob('*.ipynb'):\n",
    "    if fname[0] in ['1', '2',  '3', '4']:\n",
    "        print (\"'{}', \".format(fname) )\n",
    "        nb_list.append(fname)\n",
    "        \n",
    "def strip(nb):\n",
    "    \"\"\"\n",
    "    Keeps only the cells :\n",
    "    - starting with the first to begin with a section (that is with a ``#``)\n",
    "    - stoping with the next cell to begin with a section (that is with a ``#``)\n",
    "    \n",
    "    \"\"\"\n",
    "    start, stop = -1, len(nb.cells)\n",
    "    nb_out = nb.copy()\n",
    "    for i_cell, cell in enumerate(nb_out.cells):\n",
    "        if len(cell['source'])>0:\n",
    "            if cell['source'][0] == '#':\n",
    "                if start == -1: start = i_cell\n",
    "                else:\n",
    "                    if stop == len(nb.cells): stop = i_cell\n",
    "    if start == -1: start = 0\n",
    "    nb_out.cells = nb.cells[start:stop]\n",
    "    return nb_out\n",
    "    \n",
    "def merge_notebooks(outfile, filenames):\n",
    "    merged = None\n",
    "    for fname in filenames:\n",
    "        with open(fname, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, nbformat.NO_CONVERT)\n",
    "        \n",
    "        nb = strip(nb)\n",
    "        if merged is None:\n",
    "            merged = nb\n",
    "        else:\n",
    "            merged.cells.extend(nb.cells)\n",
    "    with open(outfile, 'w', encoding='utf-8') as f:\n",
    "        f.write(nbformat.writes(merged, nbformat.NO_CONVERT))\n",
    "merge_notebooks(name + '.ipynb', nb_list)  \n",
    "\n",
    "with open(name + '.ipynb', 'r') as f:\n",
    "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
    "\n",
    "latex_exporter = nbconvert.PDFExporter()\n",
    "latex_exporter.template_file = name # assumes it has the same name as the output\n",
    "latex_exporter.verbose = True\n",
    "(body, resources) = latex_exporter.from_notebook_node(nb)\n",
    "with open(name + '.pdf', 'w', encoding=\"iso-8859-1\") as f:\n",
    "    f.write(body.decode(encoding=\"iso-8859-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1.0-Introduction.ipynb', \n",
      "'1.1-Plan.ipynb', \n",
      "'2.0.0_SpikingNeuronModels.ipynb', \n",
      "'2.1.1_NeuralNetworks_SpikingNeuronModel.ipynb', \n",
      "'2.1.2_NeuralNetworks_Brian_OneNeuron.ipynb', \n",
      "'2.1.3_NeuralNetworks_Brian.ipynb', \n",
      "'2.1.4_NeuralNetworks_Nest.ipynb', \n",
      "'2.1.5_NeuralNetworks_pyNN_CODAvsCUBA.ipynb', \n",
      "'2.1.6_FeedForward_Exploration_I-Fcurve.ipynb', \n",
      "'2.2.1_RRNN_Presentation.ipynb', \n",
      "'2.2.2_RRNN_Exploration_control cell parameters.ipynb', \n",
      "'2.2.3_RRNN_Exploration_ModelExpVSAlpha.ipynb', \n",
      "'2.2.4_RRNN_Rasterplot_InputVariation.ipynb', \n",
      "'2.2.5_RRNN_Rasterplot_CheckingInvariants.ipynb', \n",
      "'2.2.6_RRNN_Rasterplot_GlobalWeight_Variation.ipynb', \n",
      "'2.2.7_RRNN_Exploration_Curve_Weights.ipynb', \n",
      "'2.2.8_RRNN_Exploration_Curve_Sparseness.ipynb', \n",
      "'2.2.9_RRNN_Exploration_Curve_G.ipynb', \n",
      "'2.3.1_RRNN_BalancedStates_MultiOptimisation_Intro.ipynb', \n",
      "'2.3.3_RRNN_BalancedStates_MultiOptimisation_DifferentG.ipynb', \n",
      "'3.1.1_Ring Intro.ipynb', \n",
      "'3.2.1_Ring UnTuned = input + feed-forward.ipynb', \n",
      "'3.2.2_Ring UnTuned input Homogeneous weight.ipynb', \n",
      "'3.2.3_Ring UnTuned_Bandwidths.ipynb', \n",
      "'3.2.4_Ring Untuned_FittingResponse.ipynb', \n",
      "'3.3.1_Ring_FeedForwardvsRecurrent-Rasterplots.ipynb', \n",
      "'3.3.2_Ring recurrent_Bandwidths.ipynb', \n",
      "'3.3.3_Ring recurrent_FittingResponse.ipynb', \n",
      "'4.1_Discussion et perspectives.ipynb', \n",
      "'4.2_These.ipynb', \n"
     ]
    }
   ],
   "source": [
    "%run thesis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà!\n",
    "\n",
    "## details of the method\n",
    "\n",
    "Below I will detail the method in more detail. \n",
    "\n",
    "### templating\n",
    "\n",
    "While essential to typeset documents, $\\LaTeX$ takes a while to learn and we decided to have everything written down in MarkDown, as it is native to ipython notebooks and allows to cover most of most needs, from structuring a document to writing equations. In ipython's ``nbconvert`` scheme, this involves doing the conversion machinery in a template that we simply adapted to our needs (mainly by tweeking the ``report.tplx`` file and using information around the web). Still some cosmetics could be done to pass some parameters such as author's name etc... programmatically, but that is pratictally what came out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting thesis.tplx\n"
     ]
    }
   ],
   "source": [
    "%%writefile thesis.tplx\n",
    "((*- extends 'report.tplx' -*))\n",
    "\n",
    "% Default to the notebook output style\n",
    "((* set cell_style = 'style_ipython.tplx' *))\n",
    "%((* set cell_style = 'style_bw_python.tplx' *))\n",
    "\n",
    "((* block docclass *))\n",
    "\\documentclass[french, 12pt]{report}\n",
    "((* endblock docclass *))\n",
    "\n",
    "((* block packages *))\n",
    "((( super() )))\n",
    "\\usepackage[french]{babel}%\n",
    "%\\usepackage{graphics}%\n",
    "\\usepackage{setspace}%\n",
    "\n",
    "\\newcommand{\\BookTitle}{\n",
    "{\\bf Aix-Marseille Université}\\\\\n",
    "        {\\bf Mémoire de Recherche} \\\\\n",
    "        présenté en vue de l'obtention du \\\\\n",
    "         {\\bf MASTER de NEUROSCIENCES} \\\\\n",
    "         (Spécialité: NIC)\n",
    "        }\n",
    "\\newcommand{\\Title}{OB-V1 : un modèle de détection de l'orientation dans l'aire visuelle primaire}% \n",
    "\\newcommand{\\Author}{Fernand David Arbib}%\n",
    "\\newcommand{\\AuthorB}{Laurent U.~Perrinet}%\n",
    "\\newcommand{\\Team}{\\'Equipe Inference in Visual Behaviour (InViBe)}%\n",
    "\\newcommand{\\Institute}{Institut de Neurosciences de la Timone}%\n",
    "\\newcommand{\\InstituteUMR}{UMR 7289, CNRS / Aix-Marseille Université}%\n",
    "\\newcommand{\\Address}{27, Bd. Jean Moulin, 13385 Marseille Cedex 5, France} \n",
    "\\newcommand{\\Website}{http://invibe.net/LaurentPerrinet}\n",
    "\\newcommand{\\Email}{Laurent.Perrinet@univ-amu.fr} \n",
    "                   \n",
    "((* endblock packages *))\n",
    "\n",
    "((* block h1 -*))\\chapter((* endblock h1 -*))\n",
    "((* block h2 -*))\\section((* endblock h2 -*))\n",
    "((* block h3 -*))\\subsection((* endblock h3 -*))\n",
    "((* block h4 -*))\\subsubsection((* endblock h4 -*))\n",
    "((* block h5 -*))\\paragraph((* endblock h5 -*))\n",
    "\n",
    "((* block abstract *))\n",
    "%\\tableofcontents\n",
    "~\\par\n",
    "\\newpage\n",
    "((* endblock abstract *))\n",
    "\n",
    "((* block margins *))\n",
    "\\parindent=0pt\n",
    "\\parskip=6pt\n",
    "((* endblock margins *))\n",
    "\n",
    "((* block predoc *))\n",
    "((* block title *))\n",
    "                            \\title{\\Title}\n",
    "((* endblock title *))\n",
    "((* block author *))\n",
    "                            \\author{\\Author}\n",
    "((* endblock author *))\n",
    "((* block maketitle *))     \n",
    "%\\maketitle\n",
    "\\begin{titlepage}\n",
    "\n",
    "\\begin{center}\n",
    "%\\vskip 2cm\n",
    "                   \\begin{spacing}{1.2}\n",
    "{\\Large \\BookTitle }%\n",
    "                   \\end{spacing}\n",
    "\\vskip 1cm\n",
    "                   \\begin{spacing}{1.5}\n",
    "{\\Huge \\Title }\n",
    "                   \\end{spacing}\n",
    "%\\vskip 1cm\n",
    "%\\emph{\\Large \\SubTitle }%\n",
    "\\begin{center}\n",
    "\\includegraphics{/tmp/troislogos.png} \n",
    "\\end{center}\n",
    "%\\vskip 1cm\n",
    "                   {\\renewcommand{\\arraystretch}{1.5} %<- modify value to suit your needs\n",
    "\\begin{tabular}[t]{|c|c|}\n",
    "\\hline\n",
    "Par: & {\\large \\Author}  \\\\\\hline\n",
    "Responsable de Stage: & {\\large \\AuthorB}  \\\\%\\hline\n",
    "&\\url{\\Website}\\\\%\\hline\n",
    "&\\url{\\Email}\\\\\\hline\n",
    "Laboratoire: & \\Team \\\\%\\hline\n",
    "             &          \\Institute \\\\ \n",
    "             &           \\InstituteUMR \\\\%\\hline\n",
    "             &\\Address \\\\\\hline\n",
    "\\end{tabular}\n",
    "                    }\n",
    "\\vskip .5cm\n",
    "\n",
    "\\vfill\n",
    "{\\large Juin 2016}\n",
    "%\\pageskip\n",
    "\\end{center}\n",
    "\\end{titlepage}\n",
    "\\tableofcontents\n",
    "%\\doublespacing\n",
    "                   \n",
    "((* endblock maketitle *))\n",
    "((* endblock predoc *))\n",
    "\n",
    "((* block commands *))\n",
    "    % Prevent overflowing lines due to hard-to-break entities\n",
    "    \\sloppy\n",
    "    % Setup hyperref package\n",
    "    \\hypersetup{\n",
    "      breaklinks=true, % so long urls are correctly broken across lines\n",
    "\tpdftitle={\\Title},\n",
    "\tpdfauthor={\\Author},\n",
    "\tcolorlinks=true, %colorise les liens\n",
    "\tbreaklinks=true, %permet le retour à la ligne dans les liens trop longs\n",
    "\turlcolor= blue, %couleur des hyperliens\n",
    "\tlinkcolor= blue, %couleur des liens internes\n",
    "\tcitecolor=blue,    %couleur des liens de citations\n",
    "\tbookmarksopen=false,\n",
    "\tpdftoolbar=false,\n",
    "\tpdfmenubar=false,\n",
    "%      hidelinks\n",
    "      }\n",
    "    % Slightly bigger margins than the latex defaults\n",
    "    \\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}\n",
    "\n",
    "    ((* endblock commands *))\n",
    "\n",
    "((* block bibliography *))\n",
    "\\bibliographystyle{plain}\n",
    "\\bibliography{/tmp/thesis}\n",
    "((* endblock bibliography *))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, the latex file is compiled on a temporary folder and loses track of the current working directory. One solution is to copy files in an absolute path that will be cleaned-up at the next reboot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp ../figs/troislogos.png /tmp/troislogos.png\n",
    "!cp ../figs/ring_model.png /tmp/ring_model.png\n",
    "!cp ../figs/future_model.png /tmp/future_model.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionnally, it is possible to disable selectively some cells by introduciong the following in the template:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% Disable input cells\n",
    "%((* block input_group *))\n",
    "%((* endblock input_group *))\n",
    "% Disable output cells\n",
    "%((* block output_group *))\n",
    "%((* endblock output_group *))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### including references\n",
    "\n",
    "Moreover, it is possible to include references and have that included using BibTeX. In MarkDown, it has to be fomatted like\n",
    "\n",
    "    <cite data-cite=\"Brunel2000\">(Brunel, 2000)</cite>\n",
    "\n",
    "To get somthing like <cite data-cite=\"Brunel2000\">(Brunel, 2000)</cite>. This involves of course creating a bibliography file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/thesis.bib\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/thesis.bib\n",
    "\n",
    "@article{Brunel_2007,\n",
    "\tAuthor = {Brunel, Nicolas and van Rossum, Mark C. W.},\n",
    "\tDoi = {10.1007/s00422-007-0190-0},\n",
    "\tIssn = {1432-0770},\n",
    "\tJournal = {Biol Cybern},\n",
    "\tMonth = {Oct},\n",
    "\tNumber = {5-6},\n",
    "\tPages = {337--339},\n",
    "\tPublisher = {Springer Science + Business Media},\n",
    "\tTitle = {Lapicque's 1907 paper: from frogs to integrate-and-fire},\n",
    "\tUrl = {http://dx.doi.org/10.1007/s00422-007-0190-0},\n",
    "\tVolume = {97},\n",
    "\tYear = {2007},\n",
    "\tBdsk-Url-1 = {http://dx.doi.org/10.1007/s00422-007-0190-0}}\n",
    "\n",
    "@article{Burkitt_2006,\n",
    "\tAuthor = {Burkitt, A. N.},\n",
    "\tDoi = {10.1007/s00422-006-0068-6},\n",
    "\tIssn = {1432-0770},\n",
    "\tJournal = {Biol Cybern},\n",
    "\tMonth = {Apr},\n",
    "\tNumber = {1},\n",
    "\tPages = {1--19},\n",
    "\tPublisher = {Springer Science + Business Media},\n",
    "\tTitle = {A Review of the Integrate-and-fire Neuron Model: I. Homogeneous Synaptic Input},\n",
    "\tUrl = {http://dx.doi.org/10.1007/s00422-006-0068-6},\n",
    "\tVolume = {95},\n",
    "\tYear = {2006},\n",
    "\tBdsk-Url-1 = {http://dx.doi.org/10.1007/s00422-006-0068-6}}\n",
    "\n",
    "@article{Burkitt_2006a,\n",
    "\tAuthor = {Burkitt, A. N.},\n",
    "\tDate-Modified = {2016-06-02 09:06:54 +0000},\n",
    "\tDoi = {10.1007/s00422-006-0082-8},\n",
    "\tIssn = {1432-0770},\n",
    "\tJournal = {Biol Cybern},\n",
    "\tMonth = {Jul},\n",
    "\tNumber = {2},\n",
    "\tPages = {97--112},\n",
    "\tPublisher = {Springer Science + Business Media},\n",
    "\tTitle = {A review of the integrate-and-fire neuron model: II. Inhomogeneous synaptic input and network properties},\n",
    "\tUrl = {http://dx.doi.org/10.1007/s00422-006-0082-8},\n",
    "\tVolume = {95},\n",
    "\tYear = {2006},\n",
    "\tBdsk-Url-1 = {http://dx.doi.org/10.1007/s00422-006-0082-8}}\n",
    "\n",
    "@article{Goris_2015,\n",
    "\tAuthor = {Goris, Robbe L.T. and Simoncelli, Eero P. and Movshon, J. Anthony},\n",
    "\tDoi = {10.1016/j.neuron.2015.10.009},\n",
    "\tIssn = {0896-6273},\n",
    "\tJournal = {Neuron},\n",
    "\tMonth = {Nov},\n",
    "\tNumber = {4},\n",
    "\tPages = {819--831},\n",
    "\tPublisher = {Elsevier BV},\n",
    "\tTitle = {Origin and Function of Tuning Diversity in Macaque Visual Cortex},\n",
    "\tUrl = {http://dx.doi.org/10.1016/j.neuron.2015.10.009},\n",
    "\tVolume = {88},\n",
    "\tYear = {2015},\n",
    "\tBdsk-Url-1 = {http://dx.doi.org/10.1016/j.neuron.2015.10.009}}\n",
    "\n",
    "@article{hansel1995synchrony,\n",
    "\tAuthor = {Hansel, David and Mato, Germ{\\'a}n and Meunier, Claude},\n",
    "\tDate-Added = {2016-06-02 09:07:52 +0000},\n",
    "\tDate-Modified = {2016-06-02 09:07:52 +0000},\n",
    "\tJournal = {Neural computation},\n",
    "\tNumber = {2},\n",
    "\tPages = {307--337},\n",
    "\tPublisher = {MIT Press},\n",
    "\tTitle = {Synchrony in excitatory neural networks},\n",
    "\tVolume = {7},\n",
    "\tYear = {1995}}\n",
    "\n",
    "@article{Hunter07,\n",
    "\tAbstract = {Matplotlib is a {2D} graphics package for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.},\n",
    "\tAddress = {Los Alamitos, CA, USA},\n",
    "\tAuthor = {Hunter, John D.},\n",
    "\tBooktitle = {Computing in Science \\& Engineering},\n",
    "\tCiteulike-Article-Id = {2878517},\n",
    "\tCiteulike-Linkout-0 = {http://dx.doi.org/10.1109/MCSE.2007.55},\n",
    "\tCiteulike-Linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2007.55},\n",
    "\tCiteulike-Linkout-2 = {http://dx.doi.org/10.1109/mcse.2007.55},\n",
    "\tCiteulike-Linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=4160265},\n",
    "\tDate-Added = {2016-06-02 09:06:18 +0000},\n",
    "\tDate-Modified = {2016-06-02 09:06:18 +0000},\n",
    "\tDay = {01},\n",
    "\tDoi = {10.1109/MCSE.2007.55},\n",
    "\tIssn = {1521-9615},\n",
    "\tJournal = {Computing in Science and Engineering},\n",
    "\tKeywords = {assofield, bicv-motion, bicv-sparse, kaplan13, khoei13jpp, perrinet12pred, python, reproducible-science, thesis},\n",
    "\tMonth = may,\n",
    "\tNumber = {3},\n",
    "\tPages = {90--95},\n",
    "\tPriority = {0},\n",
    "\tPublisher = {IEEE Computer Society},\n",
    "\tTitle = {Matplotlib: A {2D} Graphics Environment},\n",
    "\tUrl = {http://dx.doi.org/10.1109/MCSE.2007.55},\n",
    "\tVolume = {9},\n",
    "\tYear = {2007},\n",
    "\tBdsk-Url-1 = {http://dx.doi.org/10.1109/MCSE.2007.55}}\n",
    "\n",
    "@article{Leon12,\n",
    "\tAbstract = {Choosing an appropriate set of stimuli is essential to characterize the response of a sensory system to a particular functional dimension, such as the eye movement following the motion of a visual scene. Here, we describe a framework to generate random texture movies with controlled information content, i.e., Motion Clouds. These stimuli are defined using a generative model that is based on controlled experimental parametrization. We show that Motion Clouds correspond to dense mixing of localized moving gratings with random positions. Their global envelope is similar to natural-like stimulation with an approximate full-field translation corresponding to a retinal slip. We describe the construction of these stimuli mathematically and propose an open-source Python-based implementation. Examples of the use of this framework are shown. We also propose extensions to other modalities such as color vision, touch, and audition.},\n",
    "\tAuthor = {Sanz-Leon, Paula and Vanzetta, I. and Masson, G. S. and Perrinet, L. U.},\n",
    "\tCiteulike-Article-Id = {10461699},\n",
    "\tCiteulike-Linkout-0 = {http://dx.doi.org/10.1152/jn.00737.2011},\n",
    "\tCiteulike-Linkout-1 = {http://jn.physiology.org/content/early/2012/03/10/jn.00737.2011.abstract},\n",
    "\tCiteulike-Linkout-2 = {http://jn.physiology.org/content/early/2012/03/10/jn.00737.2011.full.pdf},\n",
    "\tCiteulike-Linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/22423003},\n",
    "\tCiteulike-Linkout-4 = {http://www.hubmed.org/display.cgi?uids=22423003},\n",
    "\tDate-Added = {2016-06-02 09:07:31 +0000},\n",
    "\tDate-Modified = {2016-06-02 09:07:31 +0000},\n",
    "\tDay = {14},\n",
    "\tDoi = {10.1152/jn.00737.2011},\n",
    "\tIssn = {1522-1598},\n",
    "\tJournal = {Journal of Neurophysiology},\n",
    "\tKeywords = {bicv-sparse, freemove, kaplan13, motion-clouds, sanz12jnp, vacher14},\n",
    "\tMonth = mar,\n",
    "\tNumber = {11},\n",
    "\tPages = {3217--3226},\n",
    "\tPmid = {22423003},\n",
    "\tPriority = {0},\n",
    "\tPublisher = {American Physiological Society},\n",
    "\tTitle = {Motion clouds: model-based stimulus synthesis of natural-like random textures for the study of motion perception},\n",
    "\tUrl = {http://dx.doi.org/10.1152/jn.00737.2011},\n",
    "\tVolume = {107},\n",
    "\tYear = {2012},\n",
    "\tBdsk-Url-1 = {http://dx.doi.org/10.1152/jn.00737.2011}}\n",
    "\n",
    "@article{Oliphant07,\n",
    "\tAbstract = {By itself, Python is an excellent \"steering\" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions.},\n",
    "\tAddress = {Los Alamitos, CA, USA},\n",
    "\tAuthor = {Oliphant, T. E.},\n",
    "\tCiteulike-Article-Id = {5662279},\n",
    "\tCiteulike-Linkout-0 = {http://dx.doi.org/10.1109/MCSE.2007.58},\n",
    "\tCiteulike-Linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2007.58},\n",
    "\tCiteulike-Linkout-2 = {http://dx.doi.org/10.1109/mcse.2007.58},\n",
    "\tCiteulike-Linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\\_all.jsp?arnumber=4160250},\n",
    "\tDate-Added = {2016-06-02 09:06:18 +0000},\n",
    "\tDate-Modified = {2016-06-02 09:06:18 +0000},\n",
    "\tDay = {01},\n",
    "\tDoi = {10.1109/MCSE.2007.58},\n",
    "\tInstitution = {Brigham Young Univ., Provo},\n",
    "\tIssn = {1521-9615},\n",
    "\tJournal = {Computing in Science and Engineering},\n",
    "\tKeywords = {assofield, bicv-motion, bicv-sparse, kaplan13, khoei13jpp, perrinet12pred, python, reproducible-science, thesis},\n",
    "\tMonth = may,\n",
    "\tNumber = {3},\n",
    "\tPages = {10--20},\n",
    "\tPriority = {0},\n",
    "\tPublisher = {IEEE Computer Society},\n",
    "\tTitle = {Python for Scientific Computing},\n",
    "\tUrl = {http://dx.doi.org/10.1109/MCSE.2007.58},\n",
    "\tVolume = {9},\n",
    "\tYear = {2007},\n",
    "\tBdsk-Url-1 = {http://dx.doi.org/10.1109/MCSE.2007.58}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merging all notebooks\n",
    "\n",
    "From all dated notebooks, we slected the one to be included in the report and ordered theme according to a hierarchical naming schemes that allowed to easily glob them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1.0-Introduction.ipynb', \n",
      "'1.1-Plan.ipynb', \n",
      "'2.0.0_SpikingNeuronModels.ipynb', \n",
      "'2.1.1_NeuralNetworks_SpikingNeuronModel.ipynb', \n",
      "'2.1.2_NeuralNetworks_Brian_OneNeuron.ipynb', \n",
      "'2.1.3_NeuralNetworks_Brian.ipynb', \n",
      "'2.1.4_NeuralNetworks_Nest.ipynb', \n",
      "'2.1.5_NeuralNetworks_pyNN_CODAvsCUBA.ipynb', \n",
      "'2.1.6_FeedForward_Exploration_I-Fcurve.ipynb', \n",
      "'2.2.1_RRNN_Presentation.ipynb', \n",
      "'2.2.2_RRNN_Exploration_control cell parameters.ipynb', \n",
      "'2.2.3_RRNN_Exploration_ModelExpVSAlpha.ipynb', \n",
      "'2.2.4_RRNN_Rasterplot_InputVariation.ipynb', \n",
      "'2.2.5_RRNN_Rasterplot_CheckingInvariants.ipynb', \n",
      "'2.2.6_RRNN_Rasterplot_GlobalWeight_Variation.ipynb', \n",
      "'2.2.7_RRNN_Exploration_Curve_Weights.ipynb', \n",
      "'2.2.8_RRNN_Exploration_Curve_Sparseness.ipynb', \n",
      "'2.2.9_RRNN_Exploration_Curve_G.ipynb', \n",
      "'2.3.1_RRNN_BalancedStates_MultiOptimisation_Intro.ipynb', \n",
      "'2.3.3_RRNN_BalancedStates_MultiOptimisation_DifferentG.ipynb', \n",
      "'3.1.1_Ring Intro.ipynb', \n",
      "'3.2.1_Ring UnTuned = input + feed-forward.ipynb', \n",
      "'3.2.2_Ring UnTuned input Homogeneous weight.ipynb', \n",
      "'3.2.3_Ring UnTuned_Bandwidths.ipynb', \n",
      "'3.2.4_Ring Untuned_FittingResponse.ipynb', \n",
      "'3.3.1_Ring_FeedForwardvsRecurrent-Rasterplots.ipynb', \n",
      "'3.3.2_Ring recurrent_Bandwidths.ipynb', \n",
      "'3.3.3_Ring recurrent_FittingResponse.ipynb', \n",
      "'4.1_Discussion et perspectives.ipynb', \n",
      "'4.2_These.ipynb', \n"
     ]
    }
   ],
   "source": [
    "if False: # manual mode\n",
    "    nb_list =['1-Introduction.ipynb', \n",
    "'2.1.1_NeuralNetworks_SpikingNeuronModel.ipynb', \n",
    "'2.1.2_NeuralNetworks_Brian_OneNeuron.ipynb', \n",
    "'2.1.3_NeuralNetworks_Brian.ipynb', \n",
    "'2.1.4_NeuralNetworks_Nest.ipynb', \n",
    "'2.1.5_NeuralNetworks_pyNN_CODAvsCUBA.ipynb', \n",
    "'2.1.6_FeedForward_Exploration_I-Fcurve.ipynb', \n",
    "'2.2.10_RRNN_Exploration_Curve_Sparseness.ipynb', \n",
    "'2.2.11_RRNN_Exploration_Curve_G.ipynb', \n",
    "'2.2.12_RRNN_Rasterplot_G.ipynb', \n",
    "'2.2.1_RRNN_Presentation.ipynb', \n",
    "'2.2.2_RRNN_Exploration_control cell parameters.ipynb', \n",
    "'2.2.3_RRNN_Exploration_ModelExpVSAlpha.ipynb', \n",
    "'2.2.4_RRNN_Rasterplot_InputVariation.ipynb', \n",
    "'2.2.5_RRNN_Rasterplot_InputWeight.ipynb', \n",
    "'2.2.6_RRNN_Exploration_I-Fcurve.ipynb', \n",
    "'2.2.7_RRNN_Rasterplot_CheckingInvariants.ipynb', \n",
    "'2.2.8_RRNN_Rasterplot_GlobalWeight_Variation.ipynb', \n",
    "'2.2.9_RRNN_Exploration_Curve_Weights.ipynb', \n",
    "'2.3.1_RRNN_BalancedStates_MultiOptimisation_Intro.ipynb', \n",
    "'2.3.2_RRNN_BalancedStates_MultiOptimisation_DifferentWeight.ipynb', \n",
    "'2.3.3_RRNN_BalancedStates_MultiOptimisation_DifferentG.ipynb', \n",
    "'3.1.1_Ring Intro.ipynb', \n",
    "'3.2.1_Ring Tuned input.ipynb', \n",
    "'3.2.2_Ring Tuned input Homogeneous weight.ipynb', \n",
    "'3.2.3_Ring Tuned_Bandwidths.ipynb', \n",
    "             ]    \n",
    "else:\n",
    "    nb_list = []\n",
    "    import glob\n",
    "    for fname in glob.glob('*.ipynb'):\n",
    "        if fname[0] in ['1', '2',  '3', '4']:\n",
    "            print (\"'{}', \".format(fname) )\n",
    "            nb_list.append(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also gives the outline of the thesis.\n",
    "\n",
    "### stripping the first block\n",
    "\n",
    "When working on a notebook, you want to be free to experiment new things or to be able to test code bits. By convention, we chose to define a \"serious block\" the rest being stripped of the the final report. by convention, we chose to keep only the cells :\n",
    "- starting with the first to begin with a section (that is with a ``#``)\n",
    "- stoping with the next cell to begin with a section (that is with a ``#``)\n",
    "\n",
    "We can experiment how to read for instance one notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells:  13\n"
     ]
    }
   ],
   "source": [
    "with open('1.0-Introduction.ipynb', 'r') as f:\n",
    "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
    "nb.cells = nb.cells[0:len(nb.cells)]\n",
    "print ('Number of cells: ', len(nb.cells))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define different blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {}, 'source': '## figures / autre notes\\n\\n(Les caractéristiques de la réponse de la plupart des neurones sélectifs à l\\'orientation, ont également été étudiées. Il existe une certaine diversité dans la courbe d\\'accord de ces neurones. En effet, la largeur de bande ou \"bandwidth\" de cette courbe varie d\\'un neurone à l\\'autre. Ainsi, la discriminabilité de l\\'orientation par les neurones du cortex visuel primaire n\\'est pas uniforme. Cette caractéristique a un effet direct sur le codage des orientations présentes dans un stimulus visuel . Les stimuli ne contenant qu\\'une seule orientation sont mieux codés par les neurones les plus sélectifs. A contrario, les stimuli riches en orientations sont mieux représentés par l\\'activité des neurones les moins sélectifs <cite data-cite=\"Goris_2015\">(Goris, 2015)</cite>.)\\n\\n![](figs/orientation_tuning.png) \\nAinsi, la perception des orientations contenues dans les différents stimuli visuels doit dépendre également de propriétés quantitatives que nous nous proposons d\\'étudier dans ce travail.\\n\\n\\n\\n\\n\\nParamètres pour balanced states :\\n\\n* g = 4\\n* w_in = 0.015\\n* w = 0.04\\n* s = 1\\n* c = 0.015\\n* p = 0.8\\n* n = 1080', 'cell_type': 'markdown'}\n",
      "-----\n",
      "0\n",
      "-----\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "-----\n",
      "1\n",
      "-----\n",
      "# Introduction\n",
      "\n",
      "## Motivation\n",
      "\n",
      "Une entité ne peut être vivante si elle n'interagit pas avec son environnement. La vie, réduit à son plus simple appareil, comporte du code génétique. Pour se perpétuer, ce code génétique doit permettre de produire des molécules qui vont former le matériel nécessaire à sa protection, à son alimentation et enfin à sa reproduction. La cellule remplit ces rôles, aussi, sa membrane et les protéines qui la constituent lui permettent de jouer un rôle d'interface entre le code génétique et l'environnement. Il apparait que la notion d'interface soit importante dans le vivant. Ainsi, l'interface se conserve et se sophistique, au fil de nombreuses mutations du code génétique et de la sélection naturelle. Cette dernière va permettre l'émergence d'interfaces de plus en plus élaborées, qui vont offrir de multiples manières de filtrer l'environnement et des moyens d'explorer celui-ci.\n",
      "\n",
      "Avec l'apparition des organismes pluricellulaires et des moyens de communications entre les cellules, les cellules se spécialisent, s'assemblent et constituent des tissus cellulaires, des organes et des systèmes qui vont permettre à l'ensemble de l'organisme d'interagir, d'une manière spécifique au système considéré, avec l'environnement. Le système nerveux en est un exemple. En effet, celui-ci permet de traiter des informations externes ou internes, et une partie de ce traitement comprend diverses fonctions que l'on regroupe dans le concept de perception.\n",
      "\n",
      "Selon l'approche neurophysiologique de la vision, la perception visuelle est construite sur la photosensibilité de certaines cellules, les cônes et les bâtonnets. Ces cellules et d'autres comme, par exemple, les cellules ganglionnaires, forment la rétine tapissant le fond de l'oeil où, à tout instant, une image de l'environnement se projette. Les cellules photosensibles vont permettre d'encoder les variations locales de luminosité composant l'image en variations de potentiel membranaire. Ces variations de potentiel vont ensuite être codées en influx nerveux qui vont être transmis dans le réseau rétinien pour y être transformés. Les informations visuelles arrivent alors au niveau du cortex visuel primaire via les entrées thalamiques. L'organisation de ce cortex est rétinotopique. Ainsi, l'activité du cortex visuel primaire représente l'espace visuel, composé d'éléments locaux comme, par exemple, les bords orientés et les couleurs. Une question se pose alors lorsqu'on cherche à associer ce substrat biologique à la perception visuelle : comment le système nerveux central réalise l'intégration de ces éléments locaux afin de constuire un percept global ?\n",
      "\n",
      "Afin de répondre à cette large problématique, il convient de s'intéresser aux divers constituants de l'image composante par composante. Ainsi, le travail qui vous est présenté est dédié à l'étude de la détection d'orientations. Il s'incrit dans un projet interdisciplinaire porté par l'équipe InViBe au sein de l'Institut de Neurosciences de la Timone. Ce projet prévoit, outre diverses expérimentations chez l'animal, une approche computationnelle des mécanismes impliqués dans cette détection d'orientations, qui constitue l'objet de ce travail.\n",
      "\n",
      "## Contexte scientifique\n",
      "\n",
      "### Organisation des orientations\n",
      "Des électrophysiologistes tels que Hubel et Wiesel ont mis en évidence, chez le chat, que des colonnes corticales du cortex visuel primaire ont une sensibilité préférentielle à une orientation possible de barres de contraste<cite data-cite=\"Hubel\">(Hubel, Wiesel, 1962)</cite>. L'avancée des études sur la sélectivité à l'orientation des neurones corticaux, montrent que le cortex visuel primaire des mammifères carnivores et des primates est comme une carte, où les neurones de même sélectivité à l'orientation sont regroupés en domaines d'iso-orientation. L'organisation particulière de ces domaines ou îlots donne lieu à des propriétés remarquables. En effet, il existe différents voisinages d'un neurone se trouvant dans le cortex visuel primaire. Si celui-ci se trouve à l'intérieur des îlots, il est à proximité de neurones de même, ou proche, sélectivité à l'orientation. Si, en revanche, toutes les orientations sont codées par son voisinage, alors il est à l'intérieur des fractures (ou pinwheels), où la sélectivité à l'orientation varie rapidement <cite data-cite=\"ohki\">(Ohki et al., 2006)</cite> <cite data-cite=\"grinvald\">(Bonhoeffer, Grinvald 1991)</cite>. Dans le cortex visuel primaire du rongeur, il n'existe pas de domaines d'iso-orientation, le voisinage d'un neurone quelconque est alors de la deuxième espèce citée.\n",
      "\n",
      "### Réponse à une orientation\n",
      "\n",
      "De telles organisations suscitent des hypothèses quant à l'intégration des informations sur l'orientation au sein des colonnes corticales du cortex visuel primaire.\n",
      "Une d'entre elles postule que la probablité de connexion entre les neurones du cortex visuel primaire est exclusivement dépendante de leur distance anatomique <cite data-cite=\"das\">(Das, Gilbert 1999)</cite>. Ce qui signifie que, dans le cas admis où il existe des connexions récurrentes et latérales au niveau cortical, les neurones à l'intérieur des domaines d'iso-orientation intègrent des informations provenant de neurones de même préférence à l'orientation. Ainsi, la réponse de ces neurones est fortement sélective et est robuste à la richesse en orientations d'un stimulus. Cela veut dire également qu'à proximité des fractures, et dans le cortex visuel primaire du rat, les neurones devraient avoir une faible sélectivité à l'orientation car ils intègrent les informations provenant de neurones sélectifs à différentes orientations. Ce n'est pourtant pas ce qui est montré expérimentalement. Une étude explique alors ce paradoxe. En effet, il a été théoriquement démontré que la réponse de ces neurones, supposés peu sélectifs, peut être plus sélective à l'orientation si le réseau du cortex visuel primaire est dans un état balancé entre l'excitation et l'inhibition <cite data-cite=\"HanselVan\">(Hansel, Van Vreeswijk 2012)</cite>.\n",
      "\n",
      "Nous nous proposons donc d'étudier la réponse d'un réseau de neurones artificiel, un ring, à différents stimuli visuels, des motion clouds <cite data-cite=\"Leon12\">(Leon)</cite>, dont nous ferons alors varier la richesse en orientations. En effet, le contenu en orientations de chaque stimulus peut être défini de façon quantitative en modulant une certaine valeur de bandwidth $B_\\theta$ caractérisant l'entrée visuelle. Le but est d'implémenter le réseau, de façon à ce qu'il possède des propriétés similaires à celles évoquées plus haut concernant le cortex visuel primaire. Nous comparerons alors la réponse de ce réseau à des données physiologiques.\n",
      "\n",
      "\n",
      "![Réseau de neurones organisé en \"ring\".](/tmp/ring_model.png)\n",
      "-----\n",
      "2\n",
      "-----\n",
      "## figures / autre notes\n",
      "\n",
      "(Les caractéristiques de la réponse de la plupart des neurones sélectifs à l'orientation, ont également été étudiées. Il existe une certaine diversité dans la courbe d'accord de ces neurones. En effet, la largeur de bande ou \"bandwidth\" de cette courbe varie d'un neurone à l'autre. Ainsi, la discriminabilité de l'orientation par les neurones du cortex visuel primaire n'est pas uniforme. Cette caractéristique a un effet direct sur le codage des orientations présentes dans un stimulus visuel . Les stimuli ne contenant qu'une seule orientation sont mieux codés par les neurones les plus sélectifs. A contrario, les stimuli riches en orientations sont mieux représentés par l'activité des neurones les moins sélectifs <cite data-cite=\"Goris_2015\">(Goris, 2015)</cite>.)\n",
      "\n",
      "![](figs/orientation_tuning.png) \n",
      "Ainsi, la perception des orientations contenues dans les différents stimuli visuels doit dépendre également de propriétés quantitatives que nous nous proposons d'étudier dans ce travail.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Paramètres pour balanced states :\n",
      "\n",
      "* g = 4\n",
      "* w_in = 0.015\n",
      "* w = 0.04\n",
      "* s = 1\n",
      "* c = 0.015\n",
      "* p = 0.8\n",
      "* n = 1080\n",
      "-----\n",
      "3\n",
      "-----\n",
      "## brouillon\n",
      "\n",
      "- chez primates et carnivores : 2 zones anatomo-fonctionnelles différentes : pinwheel et intérieur d'un patch\n",
      "- chez rat : pas d'iso-orientation\n",
      "\n",
      "gradient de sélectivité :\n",
      "couche 4 : peu de sélectivité\n",
      "couche 2-3 : bcp de sélectivité\n",
      "\n",
      "problématique dans l'intégration de la réponse :\n",
      "\n",
      "on pense que neurones à certaines PO intègrent des réponses d'autres neurones de même PO\n",
      "mais ça c'est valide qu'à l'intérieur d'un patch\n",
      "qu'en est il pour le pinwheel???\n",
      "\n",
      "- si probabilité de connexion dépend uniquement de proximité anatomique : les neurones dans pinwheel sont peu sélectifs à l'orientation\n",
      "\n",
      "- du coup V1 balancé pourrait avoir SO\n",
      "\n",
      "- plusieurs stimuli gratings, mc dont la réponse a V1 à ceux ci permet d'infirmer une des deux hypothèses.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----\n",
      "3\n",
      "-----\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def envelope(th, theta, B_theta):\n",
      "    if B_theta==np.inf:\n",
      "        env = np.ones_like(th) \n",
      "    elif B_theta==0:\n",
      "        env = np.zeros_like(th)\n",
      "        env[np.argmin(th < theta)] = 1.\n",
      "    else:\n",
      "        env = np.exp((np.cos(2*(th-theta))-1)/4/B_theta**2)\n",
      "    return env/env.max()        \n",
      "\n",
      "N_theta = 12\n",
      "bins = 180\n",
      "th = np.linspace(0, np.pi, bins, endpoint=False)\n",
      "fig, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
      "for i, B_theta_ in enumerate([np.pi/12, np.pi/4]):#[0, np.pi/64, np.pi/32, np.pi/16, np.pi/8, np.pi/4, np.pi/2, np.inf]:\n",
      "    for theta, color in zip(np.linspace(0, np.pi, N_theta, endpoint=False), \n",
      "                            [plt.cm.hsv(h) for h in np.linspace(0, 1, N_theta)]):\n",
      "        axs[i].plot(th*180/np.pi, envelope(th, theta, B_theta_), alpha=.6, color=color, lw=3)\n",
      "        axs[i].fill_between(th*180/np.pi, 0, envelope(th, theta, B_theta_), alpha=.1, color=color)\n",
      "    axs[i].set_xlim([0, 180])\n",
      "    axs[i].set_ylim([0, 1.1])\n",
      "    axs[i].set_xticks(np.linspace(0, 180, 5, endpoint=True) )#to specify number of tick…\n",
      "fig.savefig('../figs/tuning_functions.png', dpi = 600)\n",
      "\n",
      "-----\n",
      "3\n",
      "-----\n",
      "from IPython.display import FileLink, FileLinks\n",
      "FileLinks('.')\n",
      "-----\n",
      "3\n",
      "-----\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.patches import Rectangle, Arrow\n",
      "from matplotlib.colors import hsv_to_rgb\n",
      "\n",
      "def model(future=False):\n",
      "    fig = plt.figure(figsize=(8, 8))\n",
      "\n",
      "    ax2 = fig.add_subplot(111, alpha=0., axis_bgcolor=(1,1,1,0))\n",
      "    ax = fig.add_subplot(111, projection='polar', alpha=0., axis_bgcolor=(1,1,1,0))\n",
      "\n",
      "    opts= dict(ha='center', fontsize=14)\n",
      "    N = 24\n",
      "    s = 42\n",
      "    theta = np.linspace(0, 2*np.pi, N+1, endpoint=True)\n",
      "\n",
      "    ## connexions\n",
      "    N_arrow = 3\n",
      "    dthetas = alphas = np.linspace(-N_arrow, N_arrow, 2*N_arrow+1, endpoint=True)\n",
      "    dthetas *= 1.75*np.pi/N\n",
      "    alphas = np.exp( - alphas**2/ .4**2 / 2)\n",
      "    #print(alphas)\n",
      "    for dtheta, alpha in zip(dthetas, alphas):\n",
      "        plt.arrow(np.pi/2, 1.4, dtheta, -.2, color='k', alpha=alpha)\n",
      "\n",
      "        plt.arrow(0, 1.1, dtheta, -.1, color='r', alpha=alpha)\n",
      "        plt.arrow(0, 1.1, dtheta, 0., color='r', alpha=alpha)\n",
      "\n",
      "        plt.arrow(np.pi, .9, dtheta, .1, color='b', alpha=alpha)\n",
      "        plt.arrow(np.pi, .9, dtheta, 0., color='b', alpha=alpha)\n",
      "        #set_connectionstyle(\"arc,angleA=0,armA=30,rad=10\")\n",
      "        #set_arrowstyle(\"Fancy,head_length=0.2\")\n",
      "\n",
      "    ## neurones\n",
      "    colors = theta\n",
      "    for r, c in zip([.9, 1.1, 1.4], ['b', 'r', 'k']):\n",
      "        ax.plot(theta, r*np.ones_like(theta), c=c, alpha=.4)\n",
      "        c = ax.scatter(theta[:-1], r*np.ones_like(theta[:-1]), c=c, s=s)\n",
      "        #c.set_alpha(0.15)\n",
      "\n",
      "    ## entrée\n",
      "    N = 1080\n",
      "    theta = np.linspace(0, 2*np.pi, N)\n",
      "    ax.fill_between(theta, 1.45, 1.45 + envelope(theta/2, np.pi/4, np.pi/24)/2.5, lw=0, color='g', alpha=.3)\n",
      "\n",
      "    ax.set_ylim((0, 1.85))\n",
      "\n",
      "    ax.text(-np.pi/2, 1.25, 'Excitateurs', **opts)\n",
      "    ax.text(-np.pi/2, .8, 'Inhibiteurs', **opts)\n",
      "    if future:\n",
      "\n",
      "        ax.text(np.pi/2, 1.6, 'Entrée\\ndirectionnelle', **opts)\n",
      "        ax.text(-np.pi/2, 1.55, 'convergence corticale', **opts)\n",
      "    else:\n",
      "        \n",
      "        ax.text(np.pi/2, 1.6, 'Entrée\\norientationnelle', **opts)\n",
      "        ax.text(-np.pi/2, 1.55, 'convergence thalamo-corticale', **opts)\n",
      "\n",
      "    N = 12\n",
      "    for theta in np.linspace(0, 2*np.pi, N, endpoint=False):\n",
      "        r, angle, l = .15, theta, .1\n",
      "        if future:\n",
      "            ax2.add_patch(Arrow((r-l/2)*np.sin(angle)+.5, (r-l/2)*np.cos(angle)+.5, l*np.sin(angle), l*np.cos(angle), width=.06, color='k'))\n",
      "        else:\n",
      "            ax2.add_patch(Rectangle([r*np.sin(angle)+.5, r*np.cos(angle)+.5], .01, .04, angle=theta/2*180/np.pi, color=hsv_to_rgb([theta/2/np.pi, 1, 1])))            \n",
      "\n",
      "    for ax_ in [ax, ax2]:\n",
      "        ax_.grid(False, axis='both')\n",
      "\n",
      "        ax_.set_xticks([])\n",
      "        ax_.set_yticks([])\n",
      "        ax_.set_axis_off()\n",
      "    \n",
      "    fig.subplots_adjust(hspace = .0, wspace = .0, left=0.01, bottom=0.01, right=.99, top=.99)\n",
      "    return fig, ax\n",
      "-----\n",
      "3\n",
      "-----\n",
      "fig, ax = model()\n",
      "fig.savefig('../figs/ring_model.png', dpi=600)\n",
      "-----\n",
      "3\n",
      "-----\n",
      "fig, ax = model(future=True)\n",
      "fig.savefig('../figs/future_model.png', dpi=600)\n",
      "-----\n",
      "4\n",
      "-----\n",
      "### more code\n",
      "-----\n",
      "4\n",
      "-----\n",
      "fig = plt.figure(figsize=(8, 8))\n",
      "ax = plt.subplot(111)\n",
      "\n",
      "N = 12\n",
      "s = 42\n",
      "for theta in np.linspace(0, 2*np.pi, N, endpoint=False):\n",
      "    r, angle = .35, theta#\n",
      "    ax.add_patch(Rectangle([r*np.sin(angle-0.*np.pi/N/2)+.5, r*np.cos(angle-0.*np.pi/N/2)+.5], .01, .04, angle=theta/2*180/np.pi, color=hsv_to_rgb([theta/2/np.pi, 1, 1])))\n",
      "\n",
      "ax.grid(True, axis='both')\n",
      "\n",
      "#ax.set_xticks([])\n",
      "#ax.set_yticks([])\n",
      "#ax.set_axis_off()\n",
      "#fig.tight_layout()\n",
      "-----\n",
      "4\n",
      "-----\n",
      "from matplotlib.patches import Rectangle\n",
      "from matplotlib.colors import hsv_to_rgb\n",
      "fig = plt.figure(figsize=(8, 8))\n",
      "ax = plt.subplot(111)\n",
      "\n",
      "N = 12\n",
      "s = 42\n",
      "for theta in np.linspace(0, 2*np.pi, N, endpoint=False):\n",
      "    r, angle, l = .35, theta, .1\n",
      "    ax.add_patch(Arrow(r*np.sin(angle)+.5, r*np.cos(angle)+.5, l*np.sin(angle), l*np.cos(angle), width=.06, color='k'))\n",
      "\n",
      "ax.grid(True, axis='both')\n",
      "\n",
      "#ax.set_xticks([])\n",
      "#ax.set_yticks([])\n",
      "#ax.set_axis_off()\n",
      "#fig.tight_layout()\n",
      "-----\n",
      "4\n",
      "-----\n",
      "\n",
      "fig = plt.figure(figsize=(8, 8))\n",
      "\n",
      "ax2 = fig.add_subplot(111, alpha=0., axis_bgcolor=(1,1,1,0))\n",
      "ax = fig.add_subplot(111, projection='polar', alpha=0., axis_bgcolor=(1,1,1,0))\n",
      "\n",
      "ax2.grid(False, axis='both')\n",
      "\n",
      "## entrée\n",
      "N = 1080\n",
      "theta = np.linspace(0, 2*np.pi, N)\n",
      "ax.fill_between(theta, 1.45, 1.45 + envelope(theta/2, np.pi/4, np.pi/24)/2.5, lw=0, color='g', alpha=.3)\n",
      "\n",
      "\n",
      "N = 12\n",
      "s = 42\n",
      "for theta in np.linspace(0, 2*np.pi, N, endpoint=False):\n",
      "    r, angle = .15, theta#\n",
      "    ax2.add_patch(Rectangle([r*np.sin(angle-np.pi/N)+.5, r*np.cos(angle-np.pi/N)+.5], .01, .04, angle=theta/2*180/np.pi, color=hsv_to_rgb([theta/2/np.pi, 1, 1])))\n",
      "\n",
      "for ax_ in [ax, ax2]:\n",
      "    ax_.grid(False, axis='both')\n",
      "\n",
      "    ax_.set_xticks([])\n",
      "    ax_.set_yticks([])\n",
      "    ax_.set_axis_off()\n",
      "fig.tight_layout()    \n"
     ]
    }
   ],
   "source": [
    "with open('1.0-Introduction.ipynb', 'r') as f:\n",
    "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
    "\n",
    "print (nb.cells[2])    \n",
    "blocks = 0    \n",
    "for cell in nb.cells:\n",
    "    if len(cell['source'])>0:\n",
    "        if cell['source'][0] == '#': \n",
    "            blocks += 1\n",
    "    print('-----')\n",
    "    print(blocks)    \n",
    "    print('-----')\n",
    "    print(cell['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can wrap up this in one function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'language_info': {'codemirror_mode': {'version': 3, 'name': 'ipython'}, 'pygments_lexer': 'ipython3', 'name': 'python', 'mimetype': 'text/x-python', 'nbconvert_exporter': 'python', 'version': '3.5.1', 'file_extension': '.py'}, 'kernelspec': {'language': 'python', 'name': 'python3', 'display_name': 'Python 3'}, 'widgets': {'state': {}, 'version': '1.1.2'}}, 'nbformat': 4, 'cells': [{'metadata': {}, 'source': '# Introduction\\n\\n## Motivation\\n\\nUne entité ne peut être vivante si elle n\\'interagit pas avec son environnement. La vie, réduit à son plus simple appareil, comporte du code génétique. Pour se perpétuer, ce code génétique doit permettre de produire des molécules qui vont former le matériel nécessaire à sa protection, à son alimentation et enfin à sa reproduction. La cellule remplit ces rôles, aussi, sa membrane et les protéines qui la constituent lui permettent de jouer un rôle d\\'interface entre le code génétique et l\\'environnement. Il apparait que la notion d\\'interface soit importante dans le vivant. Ainsi, l\\'interface se conserve et se sophistique, au fil de nombreuses mutations du code génétique et de la sélection naturelle. Cette dernière va permettre l\\'émergence d\\'interfaces de plus en plus élaborées, qui vont offrir de multiples manières de filtrer l\\'environnement et des moyens d\\'explorer celui-ci.\\n\\nAvec l\\'apparition des organismes pluricellulaires et des moyens de communications entre les cellules, les cellules se spécialisent, s\\'assemblent et constituent des tissus cellulaires, des organes et des systèmes qui vont permettre à l\\'ensemble de l\\'organisme d\\'interagir, d\\'une manière spécifique au système considéré, avec l\\'environnement. Le système nerveux en est un exemple. En effet, celui-ci permet de traiter des informations externes ou internes, et une partie de ce traitement comprend diverses fonctions que l\\'on regroupe dans le concept de perception.\\n\\nSelon l\\'approche neurophysiologique de la vision, la perception visuelle est construite sur la photosensibilité de certaines cellules, les cônes et les bâtonnets. Ces cellules et d\\'autres comme, par exemple, les cellules ganglionnaires, forment la rétine tapissant le fond de l\\'oeil où, à tout instant, une image de l\\'environnement se projette. Les cellules photosensibles vont permettre d\\'encoder les variations locales de luminosité composant l\\'image en variations de potentiel membranaire. Ces variations de potentiel vont ensuite être codées en influx nerveux qui vont être transmis dans le réseau rétinien pour y être transformés. Les informations visuelles arrivent alors au niveau du cortex visuel primaire via les entrées thalamiques. L\\'organisation de ce cortex est rétinotopique. Ainsi, l\\'activité du cortex visuel primaire représente l\\'espace visuel, composé d\\'éléments locaux comme, par exemple, les bords orientés et les couleurs. Une question se pose alors lorsqu\\'on cherche à associer ce substrat biologique à la perception visuelle : comment le système nerveux central réalise l\\'intégration de ces éléments locaux afin de constuire un percept global ?\\n\\nAfin de répondre à cette large problématique, il convient de s\\'intéresser aux divers constituants de l\\'image composante par composante. Ainsi, le travail qui vous est présenté est dédié à l\\'étude de la détection d\\'orientations. Il s\\'incrit dans un projet interdisciplinaire porté par l\\'équipe InViBe au sein de l\\'Institut de Neurosciences de la Timone. Ce projet prévoit, outre diverses expérimentations chez l\\'animal, une approche computationnelle des mécanismes impliqués dans cette détection d\\'orientations, qui constitue l\\'objet de ce travail.\\n\\n## Contexte scientifique\\n\\n### Organisation des orientations\\nDes électrophysiologistes tels que Hubel et Wiesel ont mis en évidence, chez le chat, que des colonnes corticales du cortex visuel primaire ont une sensibilité préférentielle à une orientation possible de barres de contraste<cite data-cite=\"Hubel\">(Hubel, Wiesel, 1962)</cite>. L\\'avancée des études sur la sélectivité à l\\'orientation des neurones corticaux, montrent que le cortex visuel primaire des mammifères carnivores et des primates est comme une carte, où les neurones de même sélectivité à l\\'orientation sont regroupés en domaines d\\'iso-orientation. L\\'organisation particulière de ces domaines ou îlots donne lieu à des propriétés remarquables. En effet, il existe différents voisinages d\\'un neurone se trouvant dans le cortex visuel primaire. Si celui-ci se trouve à l\\'intérieur des îlots, il est à proximité de neurones de même, ou proche, sélectivité à l\\'orientation. Si, en revanche, toutes les orientations sont codées par son voisinage, alors il est à l\\'intérieur des fractures (ou pinwheels), où la sélectivité à l\\'orientation varie rapidement <cite data-cite=\"ohki\">(Ohki et al., 2006)</cite> <cite data-cite=\"grinvald\">(Bonhoeffer, Grinvald 1991)</cite>. Dans le cortex visuel primaire du rongeur, il n\\'existe pas de domaines d\\'iso-orientation, le voisinage d\\'un neurone quelconque est alors de la deuxième espèce citée.\\n\\n### Réponse à une orientation\\n\\nDe telles organisations suscitent des hypothèses quant à l\\'intégration des informations sur l\\'orientation au sein des colonnes corticales du cortex visuel primaire.\\nUne d\\'entre elles postule que la probablité de connexion entre les neurones du cortex visuel primaire est exclusivement dépendante de leur distance anatomique <cite data-cite=\"das\">(Das, Gilbert 1999)</cite>. Ce qui signifie que, dans le cas admis où il existe des connexions récurrentes et latérales au niveau cortical, les neurones à l\\'intérieur des domaines d\\'iso-orientation intègrent des informations provenant de neurones de même préférence à l\\'orientation. Ainsi, la réponse de ces neurones est fortement sélective et est robuste à la richesse en orientations d\\'un stimulus. Cela veut dire également qu\\'à proximité des fractures, et dans le cortex visuel primaire du rat, les neurones devraient avoir une faible sélectivité à l\\'orientation car ils intègrent les informations provenant de neurones sélectifs à différentes orientations. Ce n\\'est pourtant pas ce qui est montré expérimentalement. Une étude explique alors ce paradoxe. En effet, il a été théoriquement démontré que la réponse de ces neurones, supposés peu sélectifs, peut être plus sélective à l\\'orientation si le réseau du cortex visuel primaire est dans un état balancé entre l\\'excitation et l\\'inhibition <cite data-cite=\"HanselVan\">(Hansel, Van Vreeswijk 2012)</cite>.\\n\\nNous nous proposons donc d\\'étudier la réponse d\\'un réseau de neurones artificiel, un ring, à différents stimuli visuels, des motion clouds <cite data-cite=\"Leon12\">(Leon)</cite>, dont nous ferons alors varier la richesse en orientations. En effet, le contenu en orientations de chaque stimulus peut être défini de façon quantitative en modulant une certaine valeur de bandwidth $B_\\\\theta$ caractérisant l\\'entrée visuelle. Le but est d\\'implémenter le réseau, de façon à ce qu\\'il possède des propriétés similaires à celles évoquées plus haut concernant le cortex visuel primaire. Nous comparerons alors la réponse de ce réseau à des données physiologiques.\\n\\n\\n![Réseau de neurones organisé en \"ring\".](/tmp/ring_model.png)', 'cell_type': 'markdown'}], 'nbformat_minor': 0}\n"
     ]
    }
   ],
   "source": [
    "with open('1.0-Introduction.ipynb', 'r') as f:\n",
    "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
    "\n",
    "def strip(nb):\n",
    "    \"\"\"\n",
    "    Keeps only the cells :\n",
    "    - starting with the first to begin with a section (that is with a ``#``)\n",
    "    - stoping with the next cell to begin with a section (that is with a ``#``)\n",
    "    \n",
    "    \"\"\"\n",
    "    start, stop = -1, len(nb.cells)\n",
    "    nb_out = nb.copy()\n",
    "    for i_cell, cell in enumerate(nb_out.cells):\n",
    "        if len(cell['source'])>0:\n",
    "            if cell['source'][0] == '#':\n",
    "                if start == -1: start = i_cell\n",
    "                else:\n",
    "                    if stop == len(nb.cells): stop = i_cell\n",
    "        #print(start, stop, cell['source'])\n",
    "    if start == -1: start = 0\n",
    "    nb_out.cells = nb.cells[start:stop]\n",
    "    #print(start, stop, nb_out.cells)\n",
    "    return nb_out\n",
    "    \n",
    "nb_out = strip(nb)\n",
    "print(nb_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### merging notebooks\n",
    "\n",
    "We can now merge these blocks together in one master notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_notebooks(outfile, filenames):\n",
    "    merged = None\n",
    "    for fname in filenames:\n",
    "        with open(fname, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, nbformat.NO_CONVERT)\n",
    "        nb = strip(nb)\n",
    "        if merged is None:\n",
    "            merged = nb\n",
    "        else:\n",
    "            merged.cells.extend(nb.cells)\n",
    "    with open(outfile, 'w', encoding='utf-8') as f:\n",
    "        f.write(nbformat.writes(merged, nbformat.NO_CONVERT))\n",
    "merge_notebooks(name + '.ipynb', nb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting to LaTeX and PDF\n",
    "\n",
    "Finally, we convert this notebook using ``nconvert`` and the template that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(name + '.ipynb', 'r') as f:\n",
    "    nb = nbformat.read(f, as_version=nbformat.NO_CONVERT)\n",
    "#nb.cells[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nbconvert\n",
    "#help(nbconvert.LatexExporter)\n",
    "#nbconvert.exporters.export_latex(nb)\n",
    "from traitlets.config import Config\n",
    "# 1. Import the exporter\n",
    "from nbconvert import PDFExporter\n",
    "# 2. Instantiate the exporter. We use the `basic` template for now; we'll get into\n",
    "# later about how to customize the exporter further.\n",
    "latex_exporter = PDFExporter()\n",
    "latex_exporter.template_file = 'thesis'\n",
    "latex_exporter.verbose = True\n",
    "# 3. Process the notebook we loaded earlier\n",
    "(body, resources) = latex_exporter.from_notebook_node(nb)\n",
    "# 4. write to file\n",
    "with open(name + '.pdf', 'w', encoding=\"iso-8859-1\") as f:\n",
    "    f.write(body.decode(encoding=\"iso-8859-1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now enjoy reading the thesis file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open thesis.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
