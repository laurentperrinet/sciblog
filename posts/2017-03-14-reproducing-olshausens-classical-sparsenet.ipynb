{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * This notebook tries to reproduce the learning strategy specified in the framework of the [SparseNet algorithm from Bruno Olshausen](http://redwood.berkeley.edu/bruno/sparsenet/). It allows to efficiently code natural image patches by constraining the code to be sparse.\n",
    "\n",
    " * the underlying machinery uses a similar dictionary learning as used in the [image denoising](http://scikit-learn.org/stable/_downloads/plot_image_denoising.py) example from ``sklearn`` and our aim here is to show that a novel ingredient is necessary to reproduce Olshausen's results.\n",
    "\n",
    " * All these code bits is regrouped in the [SHL scripts repository](https://github.com/bicv/SHL_scripts) (where you will also find some older matlab code). You may install it using\n",
    "\n",
    "```\n",
    "    pip install git+https://github.com/bicv/SHL_scripts\n",
    "    \n",
    "```\n",
    "\n",
    " * following this failed [PR to sklearn](https://github.com/scikit-learn/scikit-learn/pull/4693) that was argued in [this post](https://laurentperrinet.github.io/sciblog/posts/2015-05-05-reproducing-olshausens-classical-sparsenet.html)  (and following) the goal of this notebooks is to illustrate the simpler code implemented in the [SHL scripts](https://github.com/bicv/SHL_scripts)\n",
    " \n",
    " This is joint work with [Victor Boutin](https://invibe.net/LaurentPerrinet/VictorBoutin).\n",
    "\n",
    "\n",
    "\n",
    " <!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by doing a simple learning as implemented in the [image denoising](http://scikit-learn.org/stable/_downloads/plot_image_denoising.py) example from ``sklearn`` and then show the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_data() got an unexpected keyword argument 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-212282eb8dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmatname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'olshausen'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/database/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEBUG_DOWNSCALE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEBUG_DOWNSCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta_homeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_dico\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_dico\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/ABC/2017-11_cosyne/SHL_scripts/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mlearn_dico\u001b[0;34m(self, dictionary, P_cum, data, name_database, matname, record_each, folder_exp, list_figures, fname)\u001b[0m\n\u001b[1;32m    176\u001b[0m                             \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                             \u001b[0mmax_patches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_patches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                             data_cache=self.data_cache, matname=matname)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_data() got an unexpected keyword argument 'height'"
     ]
    }
   ],
   "source": [
    "from shl_scripts.shl_experiments import SHL\n",
    "DEBUG_DOWNSCALE, verbose = 1, 0\n",
    "matname = 'olshausen'\n",
    "shl = SHL(datapath='/tmp/database/', DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, verbose=verbose, eta_homeo=0.)\n",
    "fig, ax = shl.learn_dico(matname=matname).show_dico(title=matname)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in summary\n",
    "\n",
    "In this notebook, we have replicated the classical SparseNet algorithm of Olshausen on a  set of natural images. However, the dictionaries are qualitatively not the same as the one from the original paper, and this is certainly due to the lack of control in the competition during the learning phase.\n",
    "\n",
    "What differ in this implementation from the original algorithm is mainly the way that the norm of the filters is controlled. Here, ``sklearn`` simply assumes that $ || V_k ||_2 = 1$,  $\\forall k$ (with $0 <= k < n_{components}$). We will see that this may be a problem. \n",
    " \n",
    "\n",
    "Let's now try to do that [in a new notebook](https://laurentperrinet.github.io/sciblog/posts/2017-03-15-reproducing-olshausens-classical-sparsenet-part-2.html).\n",
    "\n",
    "In [an extension](https://laurentperrinet.github.io/sciblog/posts/2017-03-17-extending-olshausens-classical-sparsenet.html), we will study how homeostasis (cooperation) may be an essential ingredient to this algorithm working on a winner-take-all basis (competition). This extension has been published as Perrinet, Neural Computation (2010) (see  https://invibe.net/LaurentPerrinet/Publications/Perrinet10shl ).\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
