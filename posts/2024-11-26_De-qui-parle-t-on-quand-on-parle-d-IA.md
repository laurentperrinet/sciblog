L'intelligence artificielle (IA) fait les gros titres des media depuis qu'elle a envahi notre quotidien. Si elle nous aide à rédiger un document ou à choisir la prochaine musique que nous allons entendre, elle peut aussi contribuer à la création de nouveaux médicaments. Plus généralement, elle est à l'origine d'une révolution dans divers domaines tels que les transports, l'industrie, le commerce et les services. Elle est si omniprésente qu'elle tient aujourd'hui une place à part, à tel point qu'on a pris l'habitude de la nommer par ce nom propre : « l'IA ».

<!-- TEASER_END -->


## « Who am AI ? »

De façon souvent amusée, on la représente souvent sur la couverture des journaux ou livres spécialisés sous les traits d'un robot à l'apparence humaine, lui octroyant tantôt une personnalité positive, tantôt une personnalité effrayante. C'est oublier que depuis déjà quelques décennies, des hordes de robots-outils équipés d'intelligence artificielle occupent nos usines et automatisent la fabrication d'objets complexes, des vêtements aux voitures, en passant par toute l’électronique moderne, comme l'appareil sur lequel vous lisez sans doute ces mots. C'est avec l'émergence des agents conversationnels, popularisés par ChatGPT, qu'une nouvelle étape a été franchie. Cette IA ne contrôle plus des objets mécaniques, mais se rapproche distinctement des capacités humaines en matière de création de contenu. 

L'une des conséquences de ce changement de paradigme est la personnification de cette technologie, de sorte qu'il n'est pas rare d'entendre dire : « Donnons ce problème à résoudre à l'IA » ou encore « C'est la faute de l'IA ! ». Prenons alors du recul pour découvrir ce qui se cache derrière ce terme. Par définition, l'IA est un domaine de la recherche scientifique qui vise à créer des machines (robotiques ou logicielles) capables d'accomplir des tâches généralement considérées comme relevant de l'intelligence humaine. Dans ce but, elle regroupe des disciplines telles que la robotique, l'informatique, les mathématiques et les neurosciences. Ces systèmes s'appuient sur des techniques d'apprentissage utilisant des bases de données massives avec pour but de simuler la réalisation de tâches données. L'IA ne se limite donc pas à une seule forme, mais se décline en d'innombrables applications.

## L’intelligence artificielle reste avant tout une machine.

En plongeant dans les rouages de ces systèmes complexes, souvent paramétrés par des milliards de réglages minutieux, on se rend compte que si ces technologies sont simplement des machines, elles sont redoutablement efficaces. En microbiologie, le système AlphaFold révolutionne le domaine en permettant de prévoir la configuration spatiale des protéines en quelques minutes seulement, alors que cette tâche prenait plusieurs jours il y a quelques années. En neurosciences, les progrès récents de l'apprentissage automatique permettent d'interagir avec les signaux d'activité neurale de telle sorte que, dans les années à venir, des personnes puissent communiquer par la pensée. On peut aussi se prendre à rêver qu'un jour, il deviendra possible d'étendre cette IA à d'autres espèces vivantes, comme les chats ou les oiseaux, ouvrant ainsi la voie à une communication inter-espèce qui bouleverserait notre [rapport](https://trustmyscience.com/intelligence-artificielle-parler-aux-animaux/) à l'[environnement](https://www.scientificamerican.com/article/how-scientists-are-using-ai-to-talk-to-animals/).

Les domaines d'application sont infinis ! On comprend alors mieux qu'à l'aune de ces découvertes, ces technologies impliquent des enjeux majeurs pour nos sociétés. Ce n'est pas sans conséquences. D'ores et déjà, les visages dans les publicités sont majoritairement générés de façon totalement artificielle et [ne correspondent plus à des personnes réelles](https://blog.hubspot.fr/marketing/ia-dans-campagnes-marketing-pub) et, d'après certaines estimations, l'IA générative créera en 2026 [plus de la moitié du contenu sur les réseaux sociaux](https://www.e-marketing.fr/Thematique/influences-1293/reseaux-sociaux-2216/Breves/Pres-de-50-du-contenu-sur-les-reseaux-sociaux-devraient-461932.htm).

## Une société transformée par l’intelligence artificielle.

L'IA est un outil transformateur, mais son usage généralisé représente un défi et soulève de nombreuses questions éthiques. En premier lieu, comme l’IA est majoritairement le résultat d’un apprentissage à partir de bases de données de productions humaines (photos, sons, textes, etc.), elle a tendance à reproduire les biais humains, tels que ceux liés au genre, à l'origine sociale ou à la race. Sans corriger ces biais, son utilisation indiscriminée peut contribuer à créer un cercle vicieux qui amplifie les préjugés existants, jusqu’à créer des « chambres d’écho ». Ce système s'auto-amplifiant, il conduit potentiellement à la création de réalités alternatives, comme les fameuses « fake news ». 

C'est d'autant plus dangereux que son utilisation donne l'illusion d'une discussion avec [un autre être qui penserait comme nous](https://theconversation.com/chatgpt-ma-dit-que-lillusion-de-la-discussion-avec-lia-nous-mene-a-lerreur-238443). Ainsi, il a été démontré que des utilisateurs de ChatGPT ont davantage confiance en cette IA qu'en des êtres humains, [ce qui peut les amener à changer d'avis, potentiellement sur des questions politiques](https://www.futura-sciences.com/tech/actualites/technologie-utilisateurs-ont-plus-plus-echanges-intimes-chatgpt-cela-inquiete-maison-mere-115214/). 

## Quel contrôle sur l'IA ? 

Allons encore plus loin : une majorité de ces technologies sont développées par des sociétés privées qui gardent leurs IA secrètes. OpenAI, le développeur de ChatGPT, a utilisé une part non négligeable du contenu total d'Internet, en particulier des sources libres comme Wikipédia. Cependant, cette société commerciale n'a pas divulgué les détails précis de ses processus d'entraînement et de modération. Les objectifs de cette intelligence artificielle ne sont donc pas nécessairement alignés sur ceux de l'entreprise en termes d'éthique, et le secret qui entoure son développement pose un défi quant à son évaluation et à son contrôle pour éviter des dérives potentielles. 

Ce constat est d'autant plus inquiétant que la majorité des technologies d'IA se trouvent actuellement entre les mains de grandes entreprises telles que Google, Amazon, Facebook, Apple et Microsoft (les célèbres GAFAM), alors que [des systèmes de régulation peinent à se mettre en place à l'échelle mondiale](https://theconversation.com/lechiquier-mondial-de-lia-entre-regulations-et-soft-power-233387). Le contexte de [la dernière élection états-unienne n'est pas pour autant encourageant](https://legrandcontinent.eu/fr/2024/11/21/le-retour-de-trump-menace-les-efforts-visant-a-rendre-lia-plus-sure/). 

Le respect de la vie privée et la surveillance de masse rendue possible par l'intelligence artificielle constituent alors un enjeu vital. Il est essentiel de veiller à ce que ces IA ne soient pas utilisées à des fins de surveillance, comme [cela se généralise dans l'espace public ou dans les voitures récentes](https://gizmodo.com/mozilla-new-cars-data-privacy-report-1850805416). Ceci requiert une vigilance constante pour obtenir de meilleures garanties.

# Éviter le sentiment d'abandon des utilisateurs d'IA

Cependant, avant d'y parvenir, il reste encore un long chemin à parcourir. Il est alors intéressant de comprendre pourquoi cette technologie nous semble souvent si étrange et inquiétante. Certes, l'IA est une technologie complexe et en constante innovation qui parait impossible à appréhender. Face à cette complexité d'apparence insurmontable, nombre d’utilisateurs se sentent dépassés et choisissent alors de l'utiliser aveuglément, espérant simplement en tirer avantage et abandonnant l'idée d'en considérer les risques potentiels.

En utilisant l'IA de cette manière, nous livrons à notre insu et sans contrepartie une énorme richesse [en livrant des documents à caractère personnels comme nos documents de travail ou l'ensemble de nos interactions avec ces outils](https://medium.com/illumination/ms-word-is-using-you-to-train-ai-86d6a4d87021?sk=b9193bd978b48741d4778ad003cce716). Ces données sont ensuite valorisées pour améliorer les modèles d'IA et promouvoir de nouveaux produits, mais sans forcément en connaître la finalité. Qui sait que [les employés de Tesla se partageaient les images croustillantes qu'ils pouvaient obtenir dans les voitures de la marque](https://www.reuters.com/technology/tesla-workers-shared-sensitive-images-recorded-by-customer-cars-2023-04-06/) ?

## La nécessité de former l'IA à notre image

Dans un objectif de souveraineté et de confidentialité de nos propres données, il est essentiel de passer à un nouveau modèle de fonctionnement pour garantir qu'elles ne soient pas exploitées à des fins d'espionnage industriel ou de ciblage publicitaire. Heureusement, les solutions existent. Il est concrètement possible de promouvoir des ressources libres de droit, comme les agents conversationnels développés par Mistral AI qui sont fournis avec tous leurs paramètres, et de favoriser une utilisation locale, en dehors d'un cloud géré par un GAFAM, ce qui est possible sur un ordinateur personnel grâce à GPT4all (https://www.nomic.ai/gpt4all).

Définir des objectifs pour l'IA implique également de veiller à ce que les systèmes soient conçus dans une perspective de diversité culturelle et sociale. On peut par exemple tenir compte des expériences et des besoins des personnes présentant des divergences neurologiques, comme celles dans le spectre autistique. Le véritable défi réside alors dans la nécessité de veiller à ce que toute intelligence artificielle soit développée, utilisée et réglementée de manière responsable, afin de garantir une utilisation équitable et respectueuse des droits humains, tout en évitant de la brider excessivement. 

# l'IA... ça s'apprend !

Pour atteindre cet objectif, il convient de promouvoir la diffusion large et accessible de l'IA dès l'école, ainsi que de sensibiliser le grand public au fonctionnement de cette technologie. À ce titre, pourquoi ne pas créer pour les enfants une nouvelle discipline à l'école, au même titre que les mathématiques, l'histoire ou le français, et qui soit entièrement dévolue à l’IA ? On peut aussi s'inspirer de Singapour où [une formation est proposée à tous les salariés en activité ou non pour se former à l'IA et à ses métiers](https://www.channelnewsasia.com/singapore/ai-talent-15000-jobs-training-education-national-strategy-3974591). 

Enseigner l'IA permettra aux utilisateurs de ne pas considérer la machine avec laquelle ils interagissent comme une entité propre et hors de portée, mais bien comme une création humaine, avec toutes ses diversités. Et l'IA, malgré ses progrès impressionnants, ne peut jamais remplacer notre responsabilité, car elle reste une création humaine, conçue par des individus et des groupes qui en déterminent les choix et les objectifs. 

En quelque sorte, si l'on représente souvent l'IA par un humanoïde, c'est le révélateur d'un vrai désir de la rendre plus proche de nos propres aspirations. Si ce n'est sûrement pas l'objectif de certaines sociétés privées, il existe de nombreuses solutions pour réaliser cette transformation positive de la société. En ce sens, en prenant conscience de notre tendance trompeuse à l'anthropomorphisation, l'IA perd de son aura d'humanoïde inquiétant et se révèle simplement comme un outil dont l'utilisation face aux enjeux sociétaux repose entre nos mains.